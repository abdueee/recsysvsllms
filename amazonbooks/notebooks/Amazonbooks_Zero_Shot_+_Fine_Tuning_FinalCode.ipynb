{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**LLM Zero-shot Reranker Baseline on AmazonBooks**\n",
        "\n",
        "This script runs a prompted LLM zero-shot reranker for the AmazonBooks dataset using Mistral-7B-Instruct-v0.3-bnb-4bit.\n",
        "What it does:\n",
        "\n",
        "*   Loads precomputed splits and 50-item candidate pools from the files in ../dataset/.\n",
        "*   Loads book metadata (title + summary) amazonbooks_metadata_merged_per_iid_clean.csv.\n",
        "*   Builds recent reading histories (3â€“5 items) from train_indexed.parquet.\n",
        "*   Uses a chat-style prompt to ask the LLM to rank the 50 candidate books.\n",
        "*   Post-processes the output into a full ranking.\n",
        "*   Evaluates HR@k and NDCG@k (k = 1, 5, 10, 20) on VAL and TEST.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vb_yPQHWi23h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y095UM2CfvGW",
        "outputId": "8f89b864-16a3-44ca-efb6-0a6250347064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading splits and candidate pools...\n",
            "\n",
            "Example candidate lengths (VAL, first 5 rows): [52, 52, 52, 52, 52] \n",
            "\n",
            "Raw users in TRAIN: 14064\n",
            "Raw users in VAL targets: 100\n",
            "Raw users in TEST targets: 100\n",
            "\n",
            "Users with target in pool: VAL=100  TEST=100\n",
            "Eval users in VAL (with target in pool): 100\n",
            "Eval users in TEST (with target in pool): 100\n",
            "\n",
            "VAL eval sample:\n",
            "   uid                                         candidates  target\n",
            "0    0  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   12521\n",
            "1    1  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...    8721\n",
            "2    2  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...    7313\n",
            "3    3  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   16287\n",
            "4    4  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...    5244\n",
            "\n",
            "VAL candidate size stats:\n",
            "count    100.00\n",
            "mean      51.99\n",
            "std        0.10\n",
            "min       51.00\n",
            "25%       52.00\n",
            "50%       52.00\n",
            "75%       52.00\n",
            "max       52.00\n",
            "Name: candidates, dtype: float64\n",
            "\n",
            "TEST candidate size stats:\n",
            "count    100.00\n",
            "mean      51.99\n",
            "std        0.10\n",
            "min       51.00\n",
            "25%       52.00\n",
            "50%       52.00\n",
            "75%       52.00\n",
            "max       52.00\n",
            "Name: candidates, dtype: float64\n",
            "\n",
            "VAL: fraction where target NOT in candidates (should be 0): 0.0000\n",
            "TEST: fraction where target NOT in candidates (should be 0): 0.0000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Loading splits and candidate pools...\\n\")\n",
        "\n",
        "# TRAIN: interactions used to build histories\n",
        "# Columns: [userId, itemId, ts, uid, iid]\n",
        "train_idx = pd.read_parquet(\"train_indexed.parquet\")\n",
        "\n",
        "# VAL / TEST targets (indexed)\n",
        "val_idx  = pd.read_parquet(\"val_targets_indexed.parquet\")\n",
        "test_idx = pd.read_parquet(\"test_targets_indexed.parquet\")\n",
        "\n",
        "# Candidate pools: one row per uid, 'candidates' = list of iids\n",
        "cand_val  = pd.read_parquet(\"val.parquet\")\n",
        "cand_test = pd.read_parquet(\"test.parquet\")\n",
        "\n",
        "print(\"Example candidate lengths (VAL, first 5 rows):\",\n",
        "      [len(c) for c in cand_val[\"candidates\"].head(5)],\n",
        "      \"\\n\")\n",
        "\n",
        "n_users_train_raw = train_idx[\"uid\"].nunique()\n",
        "n_users_val_raw   = val_idx[\"uid\"].nunique()\n",
        "n_users_test_raw  = test_idx[\"uid\"].nunique()\n",
        "\n",
        "print(\"Raw users in TRAIN:\", n_users_train_raw)\n",
        "print(\"Raw users in VAL targets:\", n_users_val_raw)\n",
        "print(\"Raw users in TEST targets:\", n_users_test_raw)\n",
        "print()\n",
        "\n",
        "# Coverage: ensure each user's target iid is in their candidate pool\n",
        "def mark_coverage(cands_df, targets_df, tgt_col_name: str):\n",
        "    \"\"\"\n",
        "    Merge candidate pools with targets and mark which users have their\n",
        "    true target item inside the candidate pool.\n",
        "\n",
        "    cands_df:   DataFrame with columns [uid, candidates]\n",
        "    targets_df: DataFrame with at least [uid, iid] where iid is the target item\n",
        "    tgt_col_name: name to give the target iid column in the merged result\n",
        "    \"\"\"\n",
        "    df = cands_df.merge(\n",
        "        targets_df[[\"uid\", \"iid\"]].rename(columns={\"iid\": tgt_col_name}),\n",
        "        on=\"uid\",\n",
        "        how=\"inner\",\n",
        "    )\n",
        "\n",
        "    # Ensure candidates is always a list\n",
        "    df[\"candidates\"] = df[\"candidates\"].apply(\n",
        "        lambda x: list(x) if isinstance(x, (list, tuple, np.ndarray, pd.Series)) else []\n",
        "    )\n",
        "\n",
        "    # Clean up target column: fill missing with -1 and cast to int\n",
        "    df[tgt_col_name] = df[tgt_col_name].fillna(-1).astype(int)\n",
        "\n",
        "    # Check if target is in candidate pool\n",
        "    df[\"target_in_pool\"] = [\n",
        "        int(t) in set(c) for t, c in zip(df[tgt_col_name], df[\"candidates\"])\n",
        "    ]\n",
        "\n",
        "    return df\n",
        "\n",
        "val_cov  = mark_coverage(cand_val,  val_idx,  \"target\")\n",
        "test_cov = mark_coverage(cand_test, test_idx, \"target\")\n",
        "\n",
        "# Keep only users where the target is in the candidate pool\n",
        "covered_val  = val_cov[val_cov[\"target_in_pool\"]].copy()\n",
        "covered_test = test_cov[test_cov[\"target_in_pool\"]].copy()\n",
        "\n",
        "# Eval-ready\n",
        "val_eval  = covered_val[[\"uid\", \"candidates\", \"target\"]].reset_index(drop=True)\n",
        "test_eval = covered_test[[\"uid\", \"candidates\", \"target\"]].reset_index(drop=True)\n",
        "\n",
        "print(f\"Users with target in pool: VAL={len(val_eval)}  TEST={len(test_eval)}\")\n",
        "print(\"Eval users in VAL (with target in pool):\", val_eval[\"uid\"].nunique())\n",
        "print(\"Eval users in TEST (with target in pool):\", test_eval[\"uid\"].nunique())\n",
        "print(\"\\nVAL eval sample:\")\n",
        "print(val_eval.head())\n",
        "\n",
        "#sanity check\n",
        "# 1. Candidate pool size distribution\n",
        "val_cand_lengths = val_eval[\"candidates\"].apply(len)\n",
        "test_cand_lengths = test_eval[\"candidates\"].apply(len)\n",
        "\n",
        "print(\"\\nVAL candidate size stats:\")\n",
        "print(val_cand_lengths.describe())\n",
        "print(\"\\nTEST candidate size stats:\")\n",
        "print(test_cand_lengths.describe())\n",
        "\n",
        "# 2. Check that every target is actually in its candidate list\n",
        "val_target_not_in_cands = (~val_eval.apply(lambda row: row[\"target\"] in row[\"candidates\"], axis=1)).mean()\n",
        "test_target_not_in_cands = (~test_eval.apply(lambda row: row[\"target\"] in row[\"candidates\"], axis=1)).mean()\n",
        "\n",
        "print(f\"\\nVAL: fraction where target NOT in candidates (should be 0): {val_target_not_in_cands:.4f}\")\n",
        "print(f\"TEST: fraction where target NOT in candidates (should be 0): {test_target_not_in_cands:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load metadata\n",
        "books_meta = pd.read_csv(\"amazonbooks_metadata_merged_per_iid_clean.csv\")\n",
        "\n",
        "print(\"Metadata columns before:\", books_meta.columns.tolist())\n",
        "print(\"Number of rows:\", len(books_meta))\n",
        "\n",
        "# Ensure required columns exist\n",
        "if \"description\" not in books_meta.columns:\n",
        "    books_meta[\"description\"] = \"\"\n",
        "    print(\"Added 'description' column (blank for now).\")\n",
        "\n",
        "# Clean types\n",
        "books_meta[\"title\"]       = books_meta[\"title\"].fillna(\"\").astype(str)\n",
        "books_meta[\"description\"] = books_meta[\"description\"].fillna(\"\").astype(str)\n",
        "\n",
        "#ensuring iid is int\n",
        "books_meta[\"iid\"] = books_meta[\"iid\"].astype(int)\n",
        "\n",
        "print(\"Metadata columns after:\", books_meta.columns.tolist())\n",
        "print(books_meta.head())\n",
        "\n",
        "# Build iid_to_meta dictionary\n",
        "iid_to_meta = {}\n",
        "\n",
        "for _, row in books_meta.iterrows():\n",
        "    iid   = int(row[\"iid\"])\n",
        "    title = row[\"title\"].strip()\n",
        "    desc  = row[\"description\"].strip()\n",
        "\n",
        "    # Take only the first sentence and cap the length\n",
        "    first_sentence = desc.split(\".\")[0].strip()\n",
        "    short_desc = first_sentence[:160]\n",
        "\n",
        "    iid_to_meta[iid] = {\n",
        "        \"title\": title,\n",
        "        \"short_desc\": short_desc,\n",
        "    }\n",
        "\n",
        "print(\"iid_to_meta loaded with\", len(iid_to_meta), \"items.\")\n",
        "\n",
        "#check metadata coverage over candidates\n",
        "def metadata_coverage(eval_df, iid_to_meta, n_users=50):\n",
        "    subset = eval_df.head(n_users)\n",
        "    total = 0\n",
        "    with_meta = 0\n",
        "    for _, row in subset.iterrows():\n",
        "        for iid in row[\"candidates\"]:\n",
        "            total += 1\n",
        "            if int(iid) in iid_to_meta:\n",
        "                with_meta += 1\n",
        "    return with_meta / total if total > 0 else 0.0\n",
        "\n",
        "val_meta_cov = metadata_coverage(val_eval, iid_to_meta, n_users=100)\n",
        "test_meta_cov = metadata_coverage(test_eval, iid_to_meta, n_users=100)\n",
        "\n",
        "print(f\"\\nMetadata coverage on VAL candidates (first 100 users): {val_meta_cov:.3f}\")\n",
        "print(f\"Metadata coverage on TEST candidates (first 100 users): {test_meta_cov:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXJjFGFCgJpD",
        "outputId": "3cef60c3-064c-41ca-d623-105729d9421e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata columns before: ['itemId', 'iid', 'title', 'description']\n",
            "Number of rows: 18783\n",
            "Metadata columns after: ['itemId', 'iid', 'title', 'description']\n",
            "       itemId  iid                                              title  \\\n",
            "0  0001047655    0                              The Prodigal Daughter   \n",
            "1  0001047736    1                                Summer of the Danes   \n",
            "2  0001047876    2                             Life of Samuel Johnson   \n",
            "3  0001048228    3                                    Pale Battalions   \n",
            "4  0001049143    4  The Poems & Songs of Robert Burns (HarperColli...   \n",
            "\n",
            "                                         description  \n",
            "0  I read Kane & Abel and think it was perhaps th...  \n",
            "1  It is not the summer of his discontent, washed...  \n",
            "2  I liked this but prefer the unabridged edition...  \n",
            "3  It is difficult to be so subtle and so dazzlin...  \n",
            "4  Many years ago, a friend with grandparents fro...  \n",
            "iid_to_meta loaded with 18783 items.\n",
            "\n",
            "Metadata coverage on VAL candidates (first 100 users): 1.000\n",
            "Metadata coverage on TEST candidates (first 100 users): 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_history_iids(train_df, eval_uids, max_history_items=5):\n",
        "    \"\"\"\n",
        "    For each uid in eval_uids, take their last `max_history_items` iids\n",
        "    from the training interactions and return them as a list.\n",
        "    \"\"\"\n",
        "    subset = train_df[train_df[\"uid\"].isin(eval_uids)].copy()\n",
        "    subset = subset.sort_values([\"uid\", \"ts\"])\n",
        "\n",
        "    history_df = (\n",
        "        subset\n",
        "        .groupby(\"uid\")[\"iid\"]\n",
        "        .apply(lambda x: list(x.tail(max_history_items)))\n",
        "        .reset_index(name=\"history_iids\")\n",
        "    )\n",
        "\n",
        "    return history_df\n",
        "\n",
        "# ---- VAL histories ----\n",
        "val_uids = covered_val[\"uid\"].unique()\n",
        "val_history_iids = build_history_iids(train_idx, val_uids, max_history_items=5)\n",
        "\n",
        "print(\"VAL history_iids sample:\")\n",
        "print(val_history_iids.head())\n",
        "print(\"Number of VAL users with history:\", len(val_history_iids))\n",
        "\n",
        "# ---- TEST histories ----\n",
        "test_uids = covered_test[\"uid\"].unique()\n",
        "test_history_iids = build_history_iids(train_idx, test_uids, max_history_items=5)\n",
        "\n",
        "print(\"TEST history_iids sample:\")\n",
        "print(test_history_iids.head())\n",
        "print(\"Number of TEST users with history:\", len(test_history_iids))\n",
        "\n",
        "val_hist_lengths = val_history_iids[\"history_iids\"].apply(len)\n",
        "test_hist_lengths = test_history_iids[\"history_iids\"].apply(len)\n",
        "\n",
        "print(\"\\nVAL history length stats:\")\n",
        "print(val_hist_lengths.describe())\n",
        "\n",
        "print(\"\\nTEST history length stats:\")\n",
        "print(test_hist_lengths.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMbseG6JgR0x",
        "outputId": "129e55f0-4679-4a6e-b893-977a114faa24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL history_iids sample:\n",
            "   uid                    history_iids\n",
            "0    0        [1043, 1044, 6435, 9755]\n",
            "1    1  [1340, 1717, 1886, 4071, 7521]\n",
            "2    2         [755, 2831, 3938, 4538]\n",
            "3    3            [3970, 14090, 14149]\n",
            "4    4         [628, 2122, 5055, 5057]\n",
            "Number of VAL users with history: 100\n",
            "TEST history_iids sample:\n",
            "   uid                    history_iids\n",
            "0    0        [1043, 1044, 6435, 9755]\n",
            "1    1  [1340, 1717, 1886, 4071, 7521]\n",
            "2    2         [755, 2831, 3938, 4538]\n",
            "3    3            [3970, 14090, 14149]\n",
            "4    4         [628, 2122, 5055, 5057]\n",
            "Number of TEST users with history: 100\n",
            "\n",
            "VAL history length stats:\n",
            "count    100.000000\n",
            "mean       4.090000\n",
            "std        0.911154\n",
            "min        3.000000\n",
            "25%        3.000000\n",
            "50%        4.000000\n",
            "75%        5.000000\n",
            "max        5.000000\n",
            "Name: history_iids, dtype: float64\n",
            "\n",
            "TEST history length stats:\n",
            "count    100.000000\n",
            "mean       4.090000\n",
            "std        0.911154\n",
            "min        3.000000\n",
            "25%        3.000000\n",
            "50%        4.000000\n",
            "75%        5.000000\n",
            "max        5.000000\n",
            "Name: history_iids, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def map_iids_to_text(iid_list, iid_to_meta, include_ids=False):\n",
        "    \"\"\"\n",
        "    Map a list of iids to human-readable strings with clear separation\n",
        "    between title and summary.\n",
        "\n",
        "    \"\"\"\n",
        "    mapped = []\n",
        "\n",
        "    for iid in iid_list:\n",
        "        meta = iid_to_meta.get(int(iid))\n",
        "        if meta is None:\n",
        "            continue\n",
        "\n",
        "        title = meta.get(\"title\", \"\").strip()\n",
        "        short = meta.get(\"short_desc\", \"\").strip()\n",
        "\n",
        "        parts = []\n",
        "        if title:\n",
        "            parts.append(f\"Title: {title}\")\n",
        "        if short:\n",
        "            parts.append(f\"Summary: {short}\")\n",
        "\n",
        "        if not parts:\n",
        "            continue\n",
        "\n",
        "        text = \" | \".join(parts)\n",
        "\n",
        "        if include_ids:\n",
        "            text = f\"ID={int(iid)} | {text}\"\n",
        "\n",
        "        mapped.append(text)\n",
        "\n",
        "    return mapped\n",
        "\n",
        "# VAL user histories mapped to readable text\n",
        "val_history_iids[\"history_text_list\"] = val_history_iids[\"history_iids\"].apply(\n",
        "    lambda ids: map_iids_to_text(ids, iid_to_meta)\n",
        ")\n",
        "\n",
        "print(\"Sample VAL history_text_list:\")\n",
        "print(val_history_iids.head())\n",
        "\n",
        "# TEST user histories mapped to readable text\n",
        "test_history_iids[\"history_text_list\"] = test_history_iids[\"history_iids\"].apply(\n",
        "    lambda ids: map_iids_to_text(ids, iid_to_meta)\n",
        ")\n",
        "\n",
        "print(\"Sample TEST history_text_list:\")\n",
        "print(test_history_iids.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mr85SDOtgVW0",
        "outputId": "171fce7f-fca2-4ec0-d46e-2cb5b526d29e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample VAL history_text_list:\n",
            "   uid                    history_iids  \\\n",
            "0    0        [1043, 1044, 6435, 9755]   \n",
            "1    1  [1340, 1717, 1886, 4071, 7521]   \n",
            "2    2         [755, 2831, 3938, 4538]   \n",
            "3    3            [3970, 14090, 14149]   \n",
            "4    4         [628, 2122, 5055, 5057]   \n",
            "\n",
            "                                   history_text_list  \n",
            "0  [Title: 20,000 Leagues Under the Sea (Progress...  \n",
            "1  [Title: The Awakening: Complete, Authoritative...  \n",
            "2  [Title: The Importance of Being Earnest (Pengu...  \n",
            "3  [Title: Holy Bible: New International Version ...  \n",
            "4  [Title: If This Is a Man and The Truce (Pengui...  \n",
            "Sample TEST history_text_list:\n",
            "   uid                    history_iids  \\\n",
            "0    0        [1043, 1044, 6435, 9755]   \n",
            "1    1  [1340, 1717, 1886, 4071, 7521]   \n",
            "2    2         [755, 2831, 3938, 4538]   \n",
            "3    3            [3970, 14090, 14149]   \n",
            "4    4         [628, 2122, 5055, 5057]   \n",
            "\n",
            "                                   history_text_list  \n",
            "0  [Title: 20,000 Leagues Under the Sea (Progress...  \n",
            "1  [Title: The Awakening: Complete, Authoritative...  \n",
            "2  [Title: The Importance of Being Earnest (Pengu...  \n",
            "3  [Title: Holy Bible: New International Version ...  \n",
            "4  [Title: If This Is a Man and The Truce (Pengui...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_history_text(history_text_list):\n",
        "    \"\"\"\n",
        "    Turn a list of book strings into a numbered history block.\n",
        "\n",
        "    \"\"\"\n",
        "    if not history_text_list:\n",
        "        return (\n",
        "            \"I have not read many books yet. \"\n",
        "            \"Please recommend from the candidate books below.\"\n",
        "        )\n",
        "\n",
        "    lines = [\"I have recently read the following books:\"]\n",
        "    for idx, book_str in enumerate(history_text_list, start=1):\n",
        "        lines.append(f\"{idx}. {book_str}\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# VAL history_text\n",
        "val_history_iids[\"history_text\"] = val_history_iids[\"history_text_list\"].apply(\n",
        "    build_history_text\n",
        ")\n",
        "print(\"Sample VAL history_text:\")\n",
        "print(val_history_iids[[\"uid\", \"history_text\"]].head(3))\n",
        "\n",
        "# TEST history_text\n",
        "test_history_iids[\"history_text\"] = test_history_iids[\"history_text_list\"].apply(\n",
        "    build_history_text\n",
        ")\n",
        "print(\"Sample TEST history_text:\")\n",
        "print(test_history_iids[[\"uid\", \"history_text\"]].head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hfWrxyqgZ9F",
        "outputId": "7be601e5-403f-4a29-c58b-4c6cc0baf901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample VAL history_text:\n",
            "   uid                                       history_text\n",
            "0    0  I have recently read the following books:\\n1. ...\n",
            "1    1  I have recently read the following books:\\n1. ...\n",
            "2    2  I have recently read the following books:\\n1. ...\n",
            "Sample TEST history_text:\n",
            "   uid                                       history_text\n",
            "0    0  I have recently read the following books:\\n1. ...\n",
            "1    1  I have recently read the following books:\\n1. ...\n",
            "2    2  I have recently read the following books:\\n1. ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map candidate pools (VAL/TEST) to candidate_books\n",
        "cand_val[\"candidate_books\"] = cand_val[\"candidates\"].apply(\n",
        "    lambda ids: map_iids_to_text(ids, iid_to_meta, include_ids=True)\n",
        ")\n",
        "\n",
        "cand_test[\"candidate_books\"] = cand_test[\"candidates\"].apply(\n",
        "    lambda ids: map_iids_to_text(ids, iid_to_meta, include_ids=True)\n",
        ")\n",
        "\n",
        "print(\"Sample mapped VAL candidates:\")\n",
        "print(cand_val.head())\n",
        "\n",
        "print(\"Sample mapped TEST candidates:\")\n",
        "print(cand_test.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbffNxBagdKB",
        "outputId": "bd295fe3-4f5d-45a9-f5dc-a0475f455427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample mapped VAL candidates:\n",
            "   uid                                         candidates  \\\n",
            "0    0  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   \n",
            "1    1  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   \n",
            "2    2  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   \n",
            "3    3  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   \n",
            "4    4  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   \n",
            "\n",
            "                                     candidate_books  \n",
            "0  [ID=7315 | Title: Harper Lee's To Kill a Mocki...  \n",
            "1  [ID=7315 | Title: Harper Lee's To Kill a Mocki...  \n",
            "2  [ID=7315 | Title: Harper Lee's To Kill a Mocki...  \n",
            "3  [ID=7315 | Title: Harper Lee's To Kill a Mocki...  \n",
            "4  [ID=7315 | Title: Harper Lee's To Kill a Mocki...  \n",
            "Sample mapped TEST candidates:\n",
            "   uid                                         candidates  \\\n",
            "0    0  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   \n",
            "1    1  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   \n",
            "2    2  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   \n",
            "3    3  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   \n",
            "4    4  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   \n",
            "\n",
            "                                     candidate_books  \n",
            "0  [ID=7315 | Title: Harper Lee's To Kill a Mocki...  \n",
            "1  [ID=7315 | Title: Harper Lee's To Kill a Mocki...  \n",
            "2  [ID=7315 | Title: Harper Lee's To Kill a Mocki...  \n",
            "3  [ID=7315 | Title: Harper Lee's To Kill a Mocki...  \n",
            "4  [ID=7315 | Title: Harper Lee's To Kill a Mocki...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge candidate pools with user histories\n",
        "# VAL\n",
        "val_merged = covered_val.merge(\n",
        "    val_history_iids[[\"uid\", \"history_text\"]],\n",
        "    on=\"uid\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "print(\"VAL merged sample:\")\n",
        "print(val_merged.head())\n",
        "print(\"VAL merged columns:\", val_merged.columns.tolist())\n",
        "\n",
        "# TEST\n",
        "test_merged = covered_test.merge(\n",
        "    test_history_iids[[\"uid\", \"history_text\"]],\n",
        "    on=\"uid\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "print(\"TEST merged sample:\")\n",
        "print(test_merged.head())\n",
        "print(\"TEST merged columns:\", test_merged.columns.tolist())\n",
        "\n",
        "print(\"\\nVAL: fraction of rows with missing history_text:\",\n",
        "      val_merged[\"history_text\"].isna().mean())\n",
        "print(\"TEST: fraction of rows with missing history_text:\",\n",
        "      test_merged[\"history_text\"].isna().mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4sMerrLghen",
        "outputId": "4bbcfd54-25c4-416a-f7ae-c4fa621b5c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL merged sample:\n",
            "   uid                                         candidates  target  \\\n",
            "0    0  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   12521   \n",
            "1    1  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...    8721   \n",
            "2    2  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...    7313   \n",
            "3    3  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   16287   \n",
            "4    4  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...    5244   \n",
            "\n",
            "   target_in_pool                                       history_text  \n",
            "0            True  I have recently read the following books:\\n1. ...  \n",
            "1            True  I have recently read the following books:\\n1. ...  \n",
            "2            True  I have recently read the following books:\\n1. ...  \n",
            "3            True  I have recently read the following books:\\n1. ...  \n",
            "4            True  I have recently read the following books:\\n1. ...  \n",
            "VAL merged columns: ['uid', 'candidates', 'target', 'target_in_pool', 'history_text']\n",
            "TEST merged sample:\n",
            "   uid                                         candidates  target  \\\n",
            "0    0  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   13418   \n",
            "1    1  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   12059   \n",
            "2    2  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   14767   \n",
            "3    3  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...   16940   \n",
            "4    4  [7315, 7908, 13042, 11033, 4582, 14470, 14754,...    9547   \n",
            "\n",
            "   target_in_pool                                       history_text  \n",
            "0            True  I have recently read the following books:\\n1. ...  \n",
            "1            True  I have recently read the following books:\\n1. ...  \n",
            "2            True  I have recently read the following books:\\n1. ...  \n",
            "3            True  I have recently read the following books:\\n1. ...  \n",
            "4            True  I have recently read the following books:\\n1. ...  \n",
            "TEST merged columns: ['uid', 'candidates', 'target', 'target_in_pool', 'history_text']\n",
            "\n",
            "VAL: fraction of rows with missing history_text: 0.0\n",
            "TEST: fraction of rows with missing history_text: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure target is int\n",
        "val_merged[\"target\"]  = val_merged[\"target\"].astype(int)\n",
        "test_merged[\"target\"] = test_merged[\"target\"].astype(int)\n",
        "\n",
        "#main DataFrames\n",
        "val_prompts_base  = val_merged.copy()\n",
        "test_prompts_base = test_merged.copy()\n",
        "\n",
        "#Adding title and summary to candidate books (WITH IDs)\n",
        "val_prompts_base[\"candidate_books\"] = val_prompts_base[\"candidates\"].apply(\n",
        "    lambda ids: map_iids_to_text(ids, iid_to_meta, include_ids=True)\n",
        ")\n",
        "\n",
        "test_prompts_base[\"candidate_books\"] = test_prompts_base[\"candidates\"].apply(\n",
        "    lambda ids: map_iids_to_text(ids, iid_to_meta, include_ids=True)\n",
        ")\n",
        "\n",
        "print(\"VAL sample candidate_books:\")\n",
        "print(val_prompts_base[[\"uid\", \"candidate_books\"]].head())\n",
        "\n",
        "print(\"\\nTEST sample candidate_books:\")\n",
        "print(test_prompts_base[[\"uid\", \"candidate_books\"]].head())\n",
        "\n",
        "print(\"VAL final base columns:\", val_prompts_base.columns.tolist())\n",
        "print(\"TEST final base columns:\", test_prompts_base.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkHl1szRgjpp",
        "outputId": "02f53359-c262-4b94-bdb1-e49a34200afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL sample candidate_books:\n",
            "   uid                                    candidate_books\n",
            "0    0  [ID=7315 | Title: Harper Lee's To Kill a Mocki...\n",
            "1    1  [ID=7315 | Title: Harper Lee's To Kill a Mocki...\n",
            "2    2  [ID=7315 | Title: Harper Lee's To Kill a Mocki...\n",
            "3    3  [ID=7315 | Title: Harper Lee's To Kill a Mocki...\n",
            "4    4  [ID=7315 | Title: Harper Lee's To Kill a Mocki...\n",
            "\n",
            "TEST sample candidate_books:\n",
            "   uid                                    candidate_books\n",
            "0    0  [ID=7315 | Title: Harper Lee's To Kill a Mocki...\n",
            "1    1  [ID=7315 | Title: Harper Lee's To Kill a Mocki...\n",
            "2    2  [ID=7315 | Title: Harper Lee's To Kill a Mocki...\n",
            "3    3  [ID=7315 | Title: Harper Lee's To Kill a Mocki...\n",
            "4    4  [ID=7315 | Title: Harper Lee's To Kill a Mocki...\n",
            "VAL final base columns: ['uid', 'candidates', 'target', 'target_in_pool', 'history_text', 'candidate_books']\n",
            "TEST final base columns: ['uid', 'candidates', 'target', 'target_in_pool', 'history_text', 'candidate_books']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect a single VAL user row in detail\n",
        "i = 5  #to choose user\n",
        "\n",
        "row = val_prompts_base.iloc[i]\n",
        "\n",
        "uid    = int(row[\"uid\"])\n",
        "target = int(row[\"target\"])\n",
        "cands  = list(row[\"candidates\"])\n",
        "\n",
        "print(f\"VAL ROW DEBUG: index={i}, uid={uid}\\n\")\n",
        "\n",
        "#Target info\n",
        "print(f\"Target iid: {target}\")\n",
        "target_meta  = iid_to_meta.get(target, {})\n",
        "t_title      = target_meta.get(\"title\", \"[NO TITLE]\").strip()\n",
        "t_short_desc = target_meta.get(\"short_desc\", \"\").strip()\n",
        "\n",
        "if t_short_desc:\n",
        "    target_text = f\"Title: {t_title} | Summary: {t_short_desc}\"\n",
        "else:\n",
        "    target_text = f\"Title: {t_title}\"\n",
        "\n",
        "print(\"Target text:\", target_text)\n",
        "print(\"\\n\")\n",
        "\n",
        "#History block shown to LLM\n",
        "print(\"HISTORY TEXT (history_text)\")\n",
        "print(row[\"history_text\"])\n",
        "print(\"\\n\")\n",
        "\n",
        "#Candidate pool: iids + title/summary\n",
        "print(\"CANDIDATE POOL (iid + text)\\n\")\n",
        "for pos, iid in enumerate(cands, start=1):\n",
        "    iid_int = int(iid)\n",
        "    meta  = iid_to_meta.get(iid_int, {})\n",
        "    title = meta.get(\"title\", \"[NO TITLE]\").strip()\n",
        "    short = meta.get(\"short_desc\", \"\").strip()\n",
        "\n",
        "    if short:\n",
        "        item_text = f\"Title: {title} | Summary: {short}\"\n",
        "    else:\n",
        "        item_text = f\"Title: {title}\"\n",
        "\n",
        "    print(f\"{pos:2d}. IID={iid_int}\")\n",
        "    print(f\"    Text: {item_text}\\n\")\n",
        "\n",
        "#If candidate_books column exists, show it too\n",
        "if \"candidate_books\" in val_prompts_base.columns:\n",
        "    print(\"candidate_books (if present)\")\n",
        "    print(row[\"candidate_books\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZM9Nd7CsOqG",
        "outputId": "32def2c2-84d0-437e-9150-3c4316984235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== VAL ROW DEBUG: index=5, uid=5 =====\n",
            "\n",
            "Target iid: 10643\n",
            "Target text: Title: Air Disaster (Vol. 1) | Summary: I've read all three Air Disaster books, and in my opinion, this is the best one\n",
            "\n",
            "\n",
            "----- HISTORY TEXT (history_text) -----\n",
            "I have recently read the following books:\n",
            "1. Title: Choice, The | Summary: It goes without saying that any book by Trask or Goodall is worth it's weight in gold\n",
            "2. Title: Unstoppable: 45 Powerful Stories of Perseverance and Triumph from People Just Like You | Summary: I enjoyed this book\n",
            "3. Title: The Five Love Languages: The Secret to Love that Lasts | Summary: I love this book, I actually already had this book in paperback, but I simply had to have it electronically so that I could have it with me at all time\n",
            "\n",
            "\n",
            "----- CANDIDATE POOL (iid + text) -----\n",
            "\n",
            " 1. IID=7315\n",
            "    Text: Title: Harper Lee's To Kill a Mockingbird (Barron's Book Notes) | Summary: At the beginning of the book, I didn't think it was very good and it was kind of boring\n",
            "\n",
            " 2. IID=7908\n",
            "    Text: Title: To Kill a Mockingbird (Acting Edition) | Summary: I thought To Kill a Mocking Bird, was a very intresting and enjoyable book\n",
            "\n",
            " 3. IID=13042\n",
            "    Text: Title: Jonathan Strange & Mr. Norrell | Summary: With one piece of work there is a new \"heavy hitter\" upon the sci fi/fantasy scene; and Susanna Clarke is her name\n",
            "\n",
            " 4. IID=11033\n",
            "    Text: Title: The Guns of August | Summary: This book is definitive in it's details yet reads like a novel\n",
            "\n",
            " 5. IID=4582\n",
            "    Text: Title: Lord Of The Rings | Summary: Though Tolkien was not the first or most critically-acclaimed fantasy writer, he remains the most beloved and influential, even though \"Lord of the Rings\" is de\n",
            "\n",
            " 6. IID=14470\n",
            "    Text: Title: The Lord of the Rings Trilogy: Three Volumes in Slipcase | Summary: Just wonderful! From one beautiful golden edged page to the last, it was pure joy\n",
            "\n",
            " 7. IID=14754\n",
            "    Text: Title: The Lord Of The Rings THREE VOLUME BOXED SET (The Fellowship Of The Ring, The Return of The King, The Two towers) | Summary: This is a wonderful audio version of the book (I am talking about the BBC cassette version)\n",
            "\n",
            " 8. IID=2831\n",
            "    Text: Title: The Importance of Being Earnest and Related Writings (Routledge English Texts) | Summary: This play is well phrased and thought out\n",
            "\n",
            " 9. IID=1886\n",
            "    Text: Title: The Awakening | Summary: This was an excellent ghost story! Usually with any ghost/mystery book, you can guess the ending mid way through the book, but not this one! Mrs\n",
            "\n",
            "10. IID=15018\n",
            "    Text: Title: Watership Down | Summary: This book was FANTASTIC! Maybe the best book that I have ever read! It is about a little group of rabbits that think danger is near, and decide to leave their h\n",
            "\n",
            "11. IID=14\n",
            "    Text: Title: Mere Christianity | Summary: I'm new to CS Lewis and this was an excellent place to start reading his work\n",
            "\n",
            "12. IID=3938\n",
            "    Text: Title: Oscar Wilde: 'The Importance of Being Earnest' (Cambridge Literature) | Summary: I loved this book!! It's a short, quick read, and definitely worth your time\n",
            "\n",
            "13. IID=4538\n",
            "    Text: Title: The Importance of Being Earnest and Other Plays (Turtleback School & Library Binding Edition) (Penguin Classics) | Summary: I loved this book!! It's a short, quick read, and definitely worth your time\n",
            "\n",
            "14. IID=12121\n",
            "    Text: Title: Brave new world,: A novel | Summary: Amazing book\n",
            "\n",
            "15. IID=1717\n",
            "    Text: Title: Awakening: Kate Chopin Pb (Case Studies in Contemporary) | Summary: I had to have this for my English CompII class\n",
            "\n",
            "16. IID=5698\n",
            "    Text: Title: Bringing Down the House: The Inside Story of Six M.I.T. Students Who Took Vegas for Millions | Summary: Wow, I was so impressed by this book\n",
            "\n",
            "17. IID=13051\n",
            "    Text: Title: The Bell Jar : A Novel (Perennial Classics) | Summary: Very well written\n",
            "\n",
            "18. IID=9562\n",
            "    Text: Title: Whitney, My Love | Summary: What a story about stubborn people and love, no wonder it's 708 pages! I loved this story\n",
            "\n",
            "19. IID=16766\n",
            "    Text: Title: Downtown: My Manhattan | Summary: excellant loved this book! Pete Hamil as an excellent historian especially when it comes to old New York\n",
            "\n",
            "20. IID=83\n",
            "    Text: Title: Gift | Summary: Mia Dolan's lifelong struggles against poverty, abusive men, and family losses makes an interesting memoir even if the psychic parts were omitted\n",
            "\n",
            "21. IID=14941\n",
            "    Text: Title: The Bell Jar (Great Books of the 20th Century) | Summary: Sylvia Plath simply wrote of her life\n",
            "\n",
            "22. IID=9999\n",
            "    Text: Title: Thunder in Jerusalem | Summary: This is great fiction\n",
            "\n",
            "23. IID=2605\n",
            "    Text: Title: Oliver Twist (Norton Critical Editions) | Summary: Dickens is incomparable to other 19th century writers and Oliver Twist is just one of many of his great moral novels\n",
            "\n",
            "24. IID=6986\n",
            "    Text: Title: Catcher in Rye (Br) (Pbk)(Oop) (Bloom's Notes) | Summary: I was in despepate need for help reading \"The Catcher in the Rye\" even though it was a good book\n",
            "\n",
            "25. IID=3614\n",
            "    Text: Title: Great Gatsby (Everyman) | Summary: not sure what or which is the more / most vacuous\n",
            "\n",
            "26. IID=755\n",
            "    Text: Title: The Importance of Being Earnest (Penguin Student Editions) | Summary: Could not be better\n",
            "\n",
            "27. IID=2300\n",
            "    Text: Title: The Duke and I (Bridgerton Series, Book 1) | Summary: As this book got started, I didn't think I'd read it to the end\n",
            "\n",
            "28. IID=7327\n",
            "    Text: Title: Z for Zachariah | Summary: Z for Zachariah is an good but not great book\n",
            "\n",
            "29. IID=108\n",
            "    Text: Title: The Great Divorce | Summary: Having read everything published by C\n",
            "\n",
            "30. IID=6484\n",
            "    Text: Title: Blue Like Jazz: Nonreligious Thoughts on Christian Spirituality | Summary: I first picked up this book after reading the fine print acknowledgements on a Nicole Nordeman CD\n",
            "\n",
            "31. IID=5358\n",
            "    Text: Title: Good to Great | Summary: Good to Great? Very Good But Not GreatJim Collins has made millions peddling his \"Good to Great\" series of books, articles, speeches, and other missives\n",
            "\n",
            "32. IID=4821\n",
            "    Text: Title: Guilty Pleasures | Summary: This book has no plot, no character development, no mystery, no real ending\n",
            "\n",
            "33. IID=4717\n",
            "    Text: Title: A Christmas Carol (Whole Story) | Summary: I discovered this book at the library three years ago but ithas since gone \"missing\" from collection, hence my purchase\n",
            "\n",
            "34. IID=6043\n",
            "    Text: Title: Brave New World | Summary: I did not like this book\n",
            "\n",
            "35. IID=757\n",
            "    Text: Title: Middlemarch (Penguin Audiobooks) | Summary: This is a must read book considering all the references to it in literature\n",
            "\n",
            "36. IID=7265\n",
            "    Text: Title: Middlemarch: A Novel of Reform (Twayne's Masterwork Studies) | Summary: Eliot in all her work from epic masterpieces like Middlemarch to small novellas like The Lifted Veil has the ability to make intelligent readers stop and re-rea\n",
            "\n",
            "37. IID=9812\n",
            "    Text: Title: A Tale of Two Cities - Literary Touchstone Edition | Summary: Charles Dickens lays out a well laid out story on the travails and tribulations faced by the rich and the poor during the French Revolution\n",
            "\n",
            "38. IID=14568\n",
            "    Text: Title: One for the Money | Summary: This book has everything\n",
            "\n",
            "39. IID=11402\n",
            "    Text: Title: Lonesome Dove | Summary: The frontier and the Old West have long been staples in American literature, and one of the best novels of the genre is Larry McMurtry's Pulitzer Prize-winning\n",
            "\n",
            "40. IID=12162\n",
            "    Text: Title: Rebecca | Summary: As a student, I chose to read \"Rebecca\" by Daphne Du Maurier because this murder mystery sounded interesting\n",
            "\n",
            "41. IID=631\n",
            "    Text: Title: The Sunne in Splendour | Summary: The Sunne in Splendour was the first novel I read by Sharon Penman, and I was enthralled immediately\n",
            "\n",
            "42. IID=4503\n",
            "    Text: Title: The Alchemist: A Fable about Following Your Dream | Summary: this book is for anyone who wants to experience life as a journey: a fantastic read\n",
            "\n",
            "43. IID=5641\n",
            "    Text: Title: A Christmas Carol, in Prose: Being a Ghost Story of Christmas (Collected Works of Charles Dickens) | Summary: Read it this past christmas to rekindle the spirit many of us loose during the year\n",
            "\n",
            "44. IID=1340\n",
            "    Text: Title: The Awakening: Complete, Authoritative Text With Biographical and Historical Contexts, Critical History, and Essays from Five Contemporary Critical ... (Case Studies in Contemporary Criticism) | Summary: From reading the readers' responses, I believe that this classic is still too subtle and complex to be appreciated by most\n",
            "\n",
            "45. IID=11334\n",
            "    Text: Title: Postmortem | Summary: Cornwell never disapoints me, with this sparkling debut she proves she on top of her genre\n",
            "\n",
            "46. IID=6487\n",
            "    Text: Title: Rachel's Tears: The Spiritual Journey of Columbine Martyr Rachel Scott | Summary: This is a beautifully written book and a tender tribute, not only to Rachel Scott's faith but to the sovereignty of God\n",
            "\n",
            "47. IID=3329\n",
            "    Text: Title: Gone with the Wind | Summary: Gone With the Wind was captivating and enjoyable\n",
            "\n",
            "48. IID=4642\n",
            "    Text: Title: Nanny Diaries | Summary: A note is left for you to organize the gift bags for your boss's dinner party, but no details are left\n",
            "\n",
            "49. IID=13284\n",
            "    Text: Title: Mother night (Bard books) | Summary: Another reviewer of this book titled his review \"Vonnegut: You can't read just one!\" Might I add that should you choose only one - This is it! In legendary Vonn\n",
            "\n",
            "50. IID=4474\n",
            "    Text: Title: Lord Of Chaos (Turtleback School & Library Binding Edition) (Wheel of Time (Pb)) | Summary: Now I want to start off saying that in the long run The Wheel Of Time is worth the boring, hair pulling needless speech that so often bubles up explaning nothin\n",
            "\n",
            "51. IID=17082\n",
            "    Text: Title: How to Stop Worrying and Start Living | Summary: I know all of us get caught up in this worring thing, but i believe this book will help you eliminate a lot of this unnessary worring\n",
            "\n",
            "52. IID=10643\n",
            "    Text: Title: Air Disaster (Vol. 1) | Summary: I've read all three Air Disaster books, and in my opinion, this is the best one\n",
            "\n",
            "----- candidate_books (if present) -----\n",
            "[\"ID=7315 | Title: Harper Lee's To Kill a Mockingbird (Barron's Book Notes) | Summary: At the beginning of the book, I didn't think it was very good and it was kind of boring\", 'ID=7908 | Title: To Kill a Mockingbird (Acting Edition) | Summary: I thought To Kill a Mocking Bird, was a very intresting and enjoyable book', 'ID=13042 | Title: Jonathan Strange & Mr. Norrell | Summary: With one piece of work there is a new \"heavy hitter\" upon the sci fi/fantasy scene; and Susanna Clarke is her name', \"ID=11033 | Title: The Guns of August | Summary: This book is definitive in it's details yet reads like a novel\", 'ID=4582 | Title: Lord Of The Rings | Summary: Though Tolkien was not the first or most critically-acclaimed fantasy writer, he remains the most beloved and influential, even though \"Lord of the Rings\" is de', 'ID=14470 | Title: The Lord of the Rings Trilogy: Three Volumes in Slipcase | Summary: Just wonderful! From one beautiful golden edged page to the last, it was pure joy', 'ID=14754 | Title: The Lord Of The Rings THREE VOLUME BOXED SET (The Fellowship Of The Ring, The Return of The King, The Two towers) | Summary: This is a wonderful audio version of the book (I am talking about the BBC cassette version)', 'ID=2831 | Title: The Importance of Being Earnest and Related Writings (Routledge English Texts) | Summary: This play is well phrased and thought out', 'ID=1886 | Title: The Awakening | Summary: This was an excellent ghost story! Usually with any ghost/mystery book, you can guess the ending mid way through the book, but not this one! Mrs', 'ID=15018 | Title: Watership Down | Summary: This book was FANTASTIC! Maybe the best book that I have ever read! It is about a little group of rabbits that think danger is near, and decide to leave their h', \"ID=14 | Title: Mere Christianity | Summary: I'm new to CS Lewis and this was an excellent place to start reading his work\", \"ID=3938 | Title: Oscar Wilde: 'The Importance of Being Earnest' (Cambridge Literature) | Summary: I loved this book!! It's a short, quick read, and definitely worth your time\", \"ID=4538 | Title: The Importance of Being Earnest and Other Plays (Turtleback School & Library Binding Edition) (Penguin Classics) | Summary: I loved this book!! It's a short, quick read, and definitely worth your time\", 'ID=12121 | Title: Brave new world,: A novel | Summary: Amazing book', 'ID=1717 | Title: Awakening: Kate Chopin Pb (Case Studies in Contemporary) | Summary: I had to have this for my English CompII class', 'ID=5698 | Title: Bringing Down the House: The Inside Story of Six M.I.T. Students Who Took Vegas for Millions | Summary: Wow, I was so impressed by this book', 'ID=13051 | Title: The Bell Jar : A Novel (Perennial Classics) | Summary: Very well written', \"ID=9562 | Title: Whitney, My Love | Summary: What a story about stubborn people and love, no wonder it's 708 pages! I loved this story\", 'ID=16766 | Title: Downtown: My Manhattan | Summary: excellant loved this book! Pete Hamil as an excellent historian especially when it comes to old New York', \"ID=83 | Title: Gift | Summary: Mia Dolan's lifelong struggles against poverty, abusive men, and family losses makes an interesting memoir even if the psychic parts were omitted\", 'ID=14941 | Title: The Bell Jar (Great Books of the 20th Century) | Summary: Sylvia Plath simply wrote of her life', 'ID=9999 | Title: Thunder in Jerusalem | Summary: This is great fiction', 'ID=2605 | Title: Oliver Twist (Norton Critical Editions) | Summary: Dickens is incomparable to other 19th century writers and Oliver Twist is just one of many of his great moral novels', 'ID=6986 | Title: Catcher in Rye (Br) (Pbk)(Oop) (Bloom\\'s Notes) | Summary: I was in despepate need for help reading \"The Catcher in the Rye\" even though it was a good book', 'ID=3614 | Title: Great Gatsby (Everyman) | Summary: not sure what or which is the more / most vacuous', 'ID=755 | Title: The Importance of Being Earnest (Penguin Student Editions) | Summary: Could not be better', \"ID=2300 | Title: The Duke and I (Bridgerton Series, Book 1) | Summary: As this book got started, I didn't think I'd read it to the end\", 'ID=7327 | Title: Z for Zachariah | Summary: Z for Zachariah is an good but not great book', 'ID=108 | Title: The Great Divorce | Summary: Having read everything published by C', 'ID=6484 | Title: Blue Like Jazz: Nonreligious Thoughts on Christian Spirituality | Summary: I first picked up this book after reading the fine print acknowledgements on a Nicole Nordeman CD', 'ID=5358 | Title: Good to Great | Summary: Good to Great? Very Good But Not GreatJim Collins has made millions peddling his \"Good to Great\" series of books, articles, speeches, and other missives', 'ID=4821 | Title: Guilty Pleasures | Summary: This book has no plot, no character development, no mystery, no real ending', 'ID=4717 | Title: A Christmas Carol (Whole Story) | Summary: I discovered this book at the library three years ago but ithas since gone \"missing\" from collection, hence my purchase', 'ID=6043 | Title: Brave New World | Summary: I did not like this book', 'ID=757 | Title: Middlemarch (Penguin Audiobooks) | Summary: This is a must read book considering all the references to it in literature', \"ID=7265 | Title: Middlemarch: A Novel of Reform (Twayne's Masterwork Studies) | Summary: Eliot in all her work from epic masterpieces like Middlemarch to small novellas like The Lifted Veil has the ability to make intelligent readers stop and re-rea\", 'ID=9812 | Title: A Tale of Two Cities - Literary Touchstone Edition | Summary: Charles Dickens lays out a well laid out story on the travails and tribulations faced by the rich and the poor during the French Revolution', 'ID=14568 | Title: One for the Money | Summary: This book has everything', \"ID=11402 | Title: Lonesome Dove | Summary: The frontier and the Old West have long been staples in American literature, and one of the best novels of the genre is Larry McMurtry's Pulitzer Prize-winning\", 'ID=12162 | Title: Rebecca | Summary: As a student, I chose to read \"Rebecca\" by Daphne Du Maurier because this murder mystery sounded interesting', 'ID=631 | Title: The Sunne in Splendour | Summary: The Sunne in Splendour was the first novel I read by Sharon Penman, and I was enthralled immediately', 'ID=4503 | Title: The Alchemist: A Fable about Following Your Dream | Summary: this book is for anyone who wants to experience life as a journey: a fantastic read', 'ID=5641 | Title: A Christmas Carol, in Prose: Being a Ghost Story of Christmas (Collected Works of Charles Dickens) | Summary: Read it this past christmas to rekindle the spirit many of us loose during the year', \"ID=1340 | Title: The Awakening: Complete, Authoritative Text With Biographical and Historical Contexts, Critical History, and Essays from Five Contemporary Critical ... (Case Studies in Contemporary Criticism) | Summary: From reading the readers' responses, I believe that this classic is still too subtle and complex to be appreciated by most\", 'ID=11334 | Title: Postmortem | Summary: Cornwell never disapoints me, with this sparkling debut she proves she on top of her genre', \"ID=6487 | Title: Rachel's Tears: The Spiritual Journey of Columbine Martyr Rachel Scott | Summary: This is a beautifully written book and a tender tribute, not only to Rachel Scott's faith but to the sovereignty of God\", 'ID=3329 | Title: Gone with the Wind | Summary: Gone With the Wind was captivating and enjoyable', \"ID=4642 | Title: Nanny Diaries | Summary: A note is left for you to organize the gift bags for your boss's dinner party, but no details are left\", 'ID=13284 | Title: Mother night (Bard books) | Summary: Another reviewer of this book titled his review \"Vonnegut: You can\\'t read just one!\" Might I add that should you choose only one - This is it! In legendary Vonn', 'ID=4474 | Title: Lord Of Chaos (Turtleback School & Library Binding Edition) (Wheel of Time (Pb)) | Summary: Now I want to start off saying that in the long run The Wheel Of Time is worth the boring, hair pulling needless speech that so often bubles up explaning nothin', 'ID=17082 | Title: How to Stop Worrying and Start Living | Summary: I know all of us get caught up in this worring thing, but i believe this book will help you eliminate a lot of this unnessary worring', \"ID=10643 | Title: Air Disaster (Vol. 1) | Summary: I've read all three Air Disaster books, and in my opinion, this is the best one\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers accelerate bitsandbytes tqdm\n",
        "\n",
        "import torch\n",
        "import json\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"unsloth/Mistral-7B-Instruct-v0.3-bnb-4bit\"\n",
        "\n",
        "print(\"Loading model:\", model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"left\"\n",
        "\n",
        "model.eval()\n",
        "print(\"Model loaded on:\", model.device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431,
          "referenced_widgets": [
            "f440fd353d294199bffbf20149330f99",
            "a221c1d096a2486195973ad27ab295a9",
            "da3a329d1e7941ddb4306d92f386ef2d",
            "3c1f36c4a23543bdab0483e89c232d4a",
            "54bc526727994001bc13aaec1a85f717",
            "c0dc5a55ded74ceeaf8dbd93fe7e3c79",
            "6e29c061bf3f4aac8452915bbdc179d4",
            "3a165eb76b0f46378a8e7568b00c6de4",
            "ec9c2ea280834e759dae3578579b0b5a",
            "a04311379f6d4a04b697ec02e99f19ca",
            "83b7785420a44d5f9fbaa4d371f81c77",
            "0ef2cc6ffc914aa4b3ad494631ca6fb9",
            "54f47dcc898a48bab6e17079238106b3",
            "6f5c7338314749b38090b0d4090dbb67",
            "31b4cccba9e84b39a51ab99036fcb0de",
            "928b089749dd4c19a531042ae3c82b6a",
            "86e7f3515a1c44beb252de2952302cf9",
            "25ab0fa13fb94136b3f4d9c15327d0a4",
            "9b4746e799064aabb93388b78dae188c",
            "b6344e8b4adb43aeb16b1d408aa39ab8",
            "8dc2b02a95a9487cad98e4d14aa21e3d",
            "95f3b2dd49b741b69f91507ff825bb96",
            "af8d49d5389c4b198d7ac91ff26ce153",
            "2dcf64b031de490ab90fb745f7db567d",
            "797ea3310bea4e67b1522ebf3262a369",
            "fa589967bcf54cda98981e2fce059e97",
            "c658b54dce9b400098edb291367324ce",
            "c9095685d81e4354a64e99a56c67aba4",
            "3e07ea221cd84a7bba038b07f635f010",
            "fe526f6ee2884f6199d25be28979d8c3",
            "94f823ad832b40c6a91bf37c7aac734d",
            "506a1325635f41c091dfd73445d329b8",
            "f9914c63f21b440b8360b30d6bcaa4a0",
            "ff7e66f40d6b4696bd9e38557762edbe",
            "85c85ed6a7b34dcca2f307ded93c6d5d",
            "de743984e6e34b6dadf75af0eedd009c",
            "61e7fe1efe9344a79a0ab072c514d8ac",
            "d18c339583134768b918b537baa79da3",
            "79015984283d4efcae7e418159ceda10",
            "6091466e372c4bb0a2d0549d3d208e1c",
            "a933146a04c84ad681c2b3b3e6cca518",
            "5f41a9267a554cde8fcfded616f7eeb7",
            "16e7395eb87b47e0b8752e70df70d123",
            "33ab54292e2545ab92685591cd941e97",
            "286371ed396e4a55931efe49db17fe79",
            "0581f0648abf417bb1baa756446d4a83",
            "b977fb9759ec405a81c6d1b47e2b3ec8",
            "78060ca672a443ff8ab957ba1aa6b793",
            "7636e857c57347e5ad0c6bc8ede65c3f",
            "4449537d6e0d43dfa8928d4a46066569",
            "2da4b28c2cbd4decb3a449ba64ac5957",
            "83a4ba6982bf406381bf4e079db46cf2",
            "04fe723dc27148d7ac4ac45ecb792697",
            "df1032cc697c4b88af74531f5d751fb9",
            "62e72651d3954d62bbee7c8c3b6261f9",
            "1b731359890942248de6417e94a7b296",
            "e3ef9414d408435fb5b25bd33eb3c622",
            "eee34f57e60c4572a21ffcbc82fa63de",
            "efaa04c749ef4805a8b55dba61d00362",
            "e55fff95ff7c49649cd65e1dfb44e170",
            "9cf2fb5afa80426b975bf22cd5f706a4",
            "e2ae77fd528b4f769932b713dec944af",
            "7e9568af9bf2442bb51becea291d0d6c",
            "d58f64550ca7427e88c30f6d4f81fe85",
            "4af291fb9e8f485393050803a0cd28a4",
            "fc2d5873271e41cabb5b592ab8b89b62",
            "f353a6baa209438ea5faa757d91e871c",
            "8ff62380789f49979d1f5cc8e8755cdc",
            "4af840e560894281b30ad7adfa8927c5",
            "154491d2e3884d71bae0edc54c5791ba",
            "413bed1e4baa4e40a7dbfdb1e87e8837",
            "5735dc7dcbc945efbe0dd2ca0ff8dbca",
            "dff2c88a3c304192af2c22b74fbe93e6",
            "e022419f83c14ea5ba02f80113a09883",
            "727e55464dc942c2ba4b5cf0f578ad87",
            "28aadb24e3104863a1d23fd7f79ee954",
            "257714f400094107b5dafa8bd20a4eea"
          ]
        },
        "id": "MgJ4qa_lgqHd",
        "outputId": "859ea9d0-a273-494b-b9cc-57f73f114ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hLoading model: unsloth/Mistral-7B-Instruct-v0.3-bnb-4bit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f440fd353d294199bffbf20149330f99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ef2cc6ffc914aa4b3ad494631ca6fb9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af8d49d5389c4b198d7ac91ff26ce153"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/446 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff7e66f40d6b4696bd9e38557762edbe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "286371ed396e4a55931efe49db17fe79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/4.14G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b731359890942248de6417e94a7b296"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/157 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f353a6baa209438ea5faa757d91e871c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = (\n",
        "    \"You are a book recommendation assistant working on a research dataset. \"\n",
        "    \"You are given a user's recent reading history and a list of candidate books. \"\n",
        "    \"Each candidate has an internal numeric ID. \"\n",
        "    \"Your job is to decide which candidate books this specific user is most \"\n",
        "    \"likely to read next, based ONLY on the information provided. \"\n",
        "    \"Assume all candidate books are equally popular and equally well-reviewed. \"\n",
        "    \"Do NOT favor famous 'classics' just because they are famous. \"\n",
        "    \"You must follow the requested output format exactly.\"\n",
        ")\n",
        "\n",
        "def build_messages_for_row(row, top_k=10):\n",
        "    \"\"\"\n",
        "    Build chat messages for a single row from val_prompts_base / test_prompts_base.\n",
        "\n",
        "    Expects columns:\n",
        "      - uid\n",
        "      - history_text         (string)\n",
        "      - candidate_books      (list of 'ID=<iid>: <text>' strings)\n",
        "    \"\"\"\n",
        "    uid = int(row[\"uid\"])\n",
        "\n",
        "    # History\n",
        "    history_text = row.get(\"history_text\", \"\")\n",
        "    if not isinstance(history_text, str) or not history_text.strip():\n",
        "        history_block = (\n",
        "            \"The user does not have much reading history.\\n\"\n",
        "            \"Please rely on the candidate book descriptions only.\"\n",
        "        )\n",
        "    else:\n",
        "        history_block = history_text\n",
        "\n",
        "    # Candidates from the precomputed column\n",
        "    candidate_books = row.get(\"candidate_books\", [])\n",
        "    if not isinstance(candidate_books, (list, tuple)) or len(candidate_books) == 0:\n",
        "        raise ValueError(f\"Row uid={uid} has no candidate_books; cannot build prompt.\")\n",
        "\n",
        "    cand_lines = [\"Candidates:\"]\n",
        "    for idx, cand_str in enumerate(candidate_books, start=1):\n",
        "        cand_lines.append(f\"{idx}. {cand_str}\")\n",
        "    candidates_block = \"\\n\".join(cand_lines)\n",
        "\n",
        "    user_content = f\"\"\"\n",
        "Here is a user and their recent reading history:\n",
        "\n",
        "{history_block}\n",
        "\n",
        "Here is a list of candidate books. Each line has an internal ID and a short description.\n",
        "\n",
        "{candidates_block}\n",
        "\n",
        "Task:\n",
        "From the candidate list, select the TOP {top_k} books this user is most likely\n",
        "to read next, ranking them from most likely to least likely.\n",
        "\n",
        "Important guidelines:\n",
        "- Assume ALL candidate books are equally popular and equally well-reviewed.\n",
        "- Do NOT favor well-known or classic books just because they are famous.\n",
        "- Base your ranking ONLY on:\n",
        "  * how similar each candidate's topic, genre, style, and tone are to the user's recent reading history; and\n",
        "  * clear patterns you can infer from the user's past books.\n",
        "- If a candidate does not fit the user's history at all, rank it lower\n",
        "  even if it is a classic or famous title.\n",
        "\n",
        "Rules about IDs and format:\n",
        "- Only choose IDs from the candidate list (e.g., ID=7315).\n",
        "- Do NOT invent new IDs or books.\n",
        "- Do NOT repeat the same ID more than once.\n",
        "- Aim to return exactly {top_k} DISTINCT IDs if possible.\n",
        "- If you are unsure about some books, still include them to reach {top_k} unique IDs.\n",
        "\n",
        "Output format:\n",
        "Return your answer as a JSON list of IDs only (as integers), in order, with no extra text.\n",
        "For example: [19089, 20536, 16114, 23872, 24429]\n",
        "\n",
        "Now return the JSON list of candidate IDs for this user.\n",
        "\"\"\".strip()\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\",   \"content\": user_content},\n",
        "    ]\n",
        "    return messages\n",
        "\n",
        "def extract_json_list(text: str):\n",
        "    first = text.find(\"[\")\n",
        "    last  = text.rfind(\"]\")\n",
        "    if first == -1 or last == -1 or last <= first:\n",
        "        return []\n",
        "    snippet = text[first:last+1]\n",
        "    try:\n",
        "        parsed = json.loads(snippet)\n",
        "        if isinstance(parsed, list):\n",
        "            return parsed\n",
        "    except Exception:\n",
        "        return []\n",
        "    return []\n",
        "\n",
        "def llm_rerank_row(row, top_k=10,\n",
        "                   max_new_tokens=256, temperature=0.0):\n",
        "    candidate_iids = list(row[\"candidates\"])\n",
        "    if not candidate_iids:\n",
        "        return [], \"\"\n",
        "\n",
        "    cand_set = set(int(x) for x in candidate_iids)\n",
        "\n",
        "    messages = build_messages_for_row(row, top_k=top_k)\n",
        "\n",
        "    input_ids = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=temperature,\n",
        "            do_sample=False,\n",
        "        )\n",
        "\n",
        "    gen_tokens = outputs[0, input_ids.shape[-1]:]\n",
        "    text = tokenizer.decode(gen_tokens, skip_special_tokens=True).strip()\n",
        "\n",
        "    raw_list = extract_json_list(text)\n",
        "\n",
        "    ranked_ids = []\n",
        "    for x in raw_list:\n",
        "        try:\n",
        "            iid_int = int(x)\n",
        "        except Exception:\n",
        "            continue\n",
        "        if iid_int in cand_set and iid_int not in ranked_ids:\n",
        "            ranked_ids.append(iid_int)\n",
        "\n",
        "    # Pad with remaining candidates (in original order) so eval always has a full ranking\n",
        "    if len(ranked_ids) < len(candidate_iids):\n",
        "        remaining = [iid for iid in candidate_iids if iid not in ranked_ids]\n",
        "        ranked_ids.extend(remaining)\n",
        "\n",
        "    return ranked_ids, text\n"
      ],
      "metadata": {
        "id": "tGNgDax2nqkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def hit_at_k(ranked_ids, target_id, k=10):\n",
        "    return 1.0 if target_id in ranked_ids[:k] else 0.0\n",
        "\n",
        "def ndcg_at_k(ranked_ids, target_id, k=10):\n",
        "    for rank, iid in enumerate(ranked_ids[:k], start=1):\n",
        "        if iid == target_id:\n",
        "            return 1.0 / math.log2(rank + 1)\n",
        "    return 0.0\n",
        "\n",
        "def eval_llm_on_split(df, split_name, top_k=10, max_users=None):\n",
        "    hits = []\n",
        "    ndcgs = []\n",
        "    logs = []\n",
        "\n",
        "    n_total = len(df)\n",
        "    n_users = n_total if max_users is None else min(n_total, max_users)\n",
        "\n",
        "    print(f\"\\nEvaluating LLM on {split_name} for {n_users} users...\")\n",
        "\n",
        "    empty_count = 0\n",
        "    short_count = 0\n",
        "\n",
        "    for idx, row in tqdm(df.iloc[:n_users].iterrows(),\n",
        "                         total=n_users, desc=f\"{split_name} users\"):\n",
        "        uid    = int(row[\"uid\"])\n",
        "        target = int(row[\"target\"])\n",
        "\n",
        "        ranked_ids, raw_text = llm_rerank_row(\n",
        "            row,\n",
        "            top_k=top_k,\n",
        "            max_new_tokens=256,\n",
        "            temperature=0.0,\n",
        "        )\n",
        "\n",
        "        if not ranked_ids:\n",
        "            empty_count += 1\n",
        "            continue\n",
        "\n",
        "        if len(ranked_ids) < top_k:\n",
        "            short_count += 1\n",
        "\n",
        "        h = hit_at_k(ranked_ids, target, k=top_k)\n",
        "        d = ndcg_at_k(ranked_ids, target, k=top_k)\n",
        "        hits.append(h)\n",
        "        ndcgs.append(d)\n",
        "\n",
        "        logs.append({\n",
        "            \"row_index\": int(idx),\n",
        "            \"uid\": uid,\n",
        "            \"target\": target,\n",
        "            \"candidate_iids\": [int(i) for i in row[\"candidates\"]],\n",
        "            \"ranked_ids\": [int(i) for i in ranked_ids],\n",
        "            \"raw_output\": raw_text,\n",
        "        })\n",
        "\n",
        "    hr   = float(np.mean(hits)) if hits else 0.0\n",
        "    ndcg = float(np.mean(ndcgs)) if ndcgs else 0.0\n",
        "\n",
        "    print(f\"[{split_name}] Zero-shot LLM HR@{top_k} = {hr:.3f}  NDCG@{top_k} = {ndcg:.3f}\")\n",
        "    print(f\"Users evaluated: {len(hits)} (out of {n_users})\")\n",
        "    print(f\"Fraction rows with empty ranking: {empty_count / n_users:.3f}\")\n",
        "    print(f\"Fraction rows with <K ranking:    {short_count / n_users:.3f}\")\n",
        "\n",
        "    return hr, ndcg, logs\n",
        "\n",
        "K_VALUES = [1, 5, 10, 20]\n",
        "\n",
        "for k in K_VALUES:\n",
        "    print(f\"\\n Evaluating Zero-Shot LLM at k = {k}\")\n",
        "    val_hr, val_ndcg, _ = eval_llm_on_split(\n",
        "        val_prompts_base,\n",
        "        split_name=\"VAL\",\n",
        "        top_k=k,\n",
        "        max_users=None,\n",
        "    )\n",
        "    print(f\"VAL HR@{k}   = {val_hr:.3f}\")\n",
        "    print(f\"VAL NDCG@{k} = {val_ndcg:.3f}\")\n",
        "\n",
        "for k in K_VALUES:\n",
        "    print(f\"\\n Evaluating Zero-Shot LLM on TEST at k = {k} \")\n",
        "    test_hr, test_ndcg, _ = eval_llm_on_split(\n",
        "        test_prompts_base,\n",
        "        split_name=\"TEST\",\n",
        "        top_k=k,\n",
        "        max_users=None,\n",
        "    )\n",
        "    print(f\"TEST HR@{k}   = {test_hr:.3f}\")\n",
        "    print(f\"TEST NDCG@{k} = {test_ndcg:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8394653-76dc-48a0-a0aa-0985d0fb4268",
        "id": "NENgUHE1zbj-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluating Zero-Shot LLM at k = 1\n",
            "\n",
            "Evaluating LLM on VAL for 100 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAL users:   0%|          | 0/100 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "VAL users: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [11:39<00:00,  6.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VAL] Zero-shot LLM HR@1 = 0.030  NDCG@1 = 0.030\n",
            "Users evaluated: 100 (out of 100)\n",
            "Fraction rows with empty ranking: 0.000\n",
            "Fraction rows with <K ranking:    0.000\n",
            "VAL HR@1   = 0.030\n",
            "VAL NDCG@1 = 0.030\n",
            "\n",
            " Evaluating Zero-Shot LLM at k = 5\n",
            "\n",
            "Evaluating LLM on VAL for 100 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAL users: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [07:59<00:00,  4.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VAL] Zero-shot LLM HR@5 = 0.100  NDCG@5 = 0.064\n",
            "Users evaluated: 100 (out of 100)\n",
            "Fraction rows with empty ranking: 0.000\n",
            "Fraction rows with <K ranking:    0.000\n",
            "VAL HR@5   = 0.100\n",
            "VAL NDCG@5 = 0.064\n",
            "\n",
            " Evaluating Zero-Shot LLM at k = 10\n",
            "\n",
            "Evaluating LLM on VAL for 100 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAL users: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [11:32<00:00,  6.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VAL] Zero-shot LLM HR@10 = 0.210  NDCG@10 = 0.094\n",
            "Users evaluated: 100 (out of 100)\n",
            "Fraction rows with empty ranking: 0.000\n",
            "Fraction rows with <K ranking:    0.000\n",
            "VAL HR@10   = 0.210\n",
            "VAL NDCG@10 = 0.094\n",
            "\n",
            " Evaluating Zero-Shot LLM at k = 20\n",
            "\n",
            "Evaluating LLM on VAL for 100 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAL users: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [19:05<00:00, 11.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VAL] Zero-shot LLM HR@20 = 0.190  NDCG@20 = 0.083\n",
            "Users evaluated: 100 (out of 100)\n",
            "Fraction rows with empty ranking: 0.000\n",
            "Fraction rows with <K ranking:    0.000\n",
            "VAL HR@20   = 0.190\n",
            "VAL NDCG@20 = 0.083\n",
            "\n",
            " Evaluating Zero-Shot LLM on TEST at k = 1 \n",
            "\n",
            "Evaluating LLM on TEST for 100 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TEST users: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [11:37<00:00,  6.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] Zero-shot LLM HR@1 = 0.020  NDCG@1 = 0.020\n",
            "Users evaluated: 100 (out of 100)\n",
            "Fraction rows with empty ranking: 0.000\n",
            "Fraction rows with <K ranking:    0.000\n",
            "TEST HR@1   = 0.020\n",
            "TEST NDCG@1 = 0.020\n",
            "\n",
            " Evaluating Zero-Shot LLM on TEST at k = 5 \n",
            "\n",
            "Evaluating LLM on TEST for 100 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TEST users: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [08:00<00:00,  4.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] Zero-shot LLM HR@5 = 0.070  NDCG@5 = 0.040\n",
            "Users evaluated: 100 (out of 100)\n",
            "Fraction rows with empty ranking: 0.000\n",
            "Fraction rows with <K ranking:    0.000\n",
            "TEST HR@5   = 0.070\n",
            "TEST NDCG@5 = 0.040\n",
            "\n",
            " Evaluating Zero-Shot LLM on TEST at k = 10 \n",
            "\n",
            "Evaluating LLM on TEST for 100 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TEST users: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [11:34<00:00,  6.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] Zero-shot LLM HR@10 = 0.100  NDCG@10 = 0.053\n",
            "Users evaluated: 100 (out of 100)\n",
            "Fraction rows with empty ranking: 0.000\n",
            "Fraction rows with <K ranking:    0.000\n",
            "TEST HR@10   = 0.100\n",
            "TEST NDCG@10 = 0.053\n",
            "\n",
            " Evaluating Zero-Shot LLM on TEST at k = 20 \n",
            "\n",
            "Evaluating LLM on TEST for 100 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TEST users: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [19:07<00:00, 11.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] Zero-shot LLM HR@20 = 0.160  NDCG@20 = 0.067\n",
            "Users evaluated: 100 (out of 100)\n",
            "Fraction rows with empty ranking: 0.000\n",
            "Fraction rows with <K ranking:    0.000\n",
            "TEST HR@20   = 0.160\n",
            "TEST NDCG@20 = 0.067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-tuning Mistral-7B-Instruct on AmazonBooks (CTR-style)**\n",
        "\n",
        "This section extends the zero-shot reranker into a fine-tuned model that learns a binary â€œYES / NOâ€ preference classifier (CTR-style). The fine-tuned model is then used to score and rank the same 50-item candidate pools used in the zero-shot evaluation.\n",
        "\n",
        "*   Build a CTR-style dataset from the AmazonBooks training interactions:\n",
        "each training example consists of (user history, candidate item, label âˆˆ {YES, NO}), with negatives sampled from items the user has not seen.\n",
        "*   Convert each example into an instruction-style prompt that shows the userâ€™s reading history, one candidate book (title + summary), and the expected answer (â€œYESâ€ or â€œNOâ€).\n",
        "*   Fine-tune the Mistral-7B-Instruct-4bit model with LoRA using Unsloth, training on the generated prompts for several hundred steps.\n",
        "*   At inference time, score each candidate in the pool with p(YES | history, candidate) and rank items by this probability.\n",
        "*   Evaluate ranking quality using HR@k and NDCG@k on the same VAL and TEST users used in the zero-shot reranker.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "acMsEXcr-esE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# CTR dataset hyperparameters\n",
        "MAX_HISTORY_LEN_CTR   = 10       # how many past items to keep per example\n",
        "NUM_NEGATIVES_PER_POS = 1        # negatives per positive\n",
        "MAX_TRAIN_EXAMPLES    = 15_000   # cap for training examples\n",
        "VAL_FRACTION          = 0.1      # later used for train/val split\n",
        "RANDOM_SEED_CTR       = 42\n",
        "\n",
        "rng = np.random.default_rng(RANDOM_SEED_CTR)\n",
        "\n",
        "#Build user-full interaction sequence (by iid)\n",
        "print(\"Building user sequences from train_idx for CTR...\")\n",
        "\n",
        "#Ensure correct sorting by time\n",
        "train_sorted_ctr = train_idx.sort_values([\"uid\", \"ts\"])\n",
        "\n",
        "#user_seqs: uid - [iid1, iid2, ..., iidT] in chronological order\n",
        "user_seqs = train_sorted_ctr.groupby(\"uid\")[\"iid\"].apply(list).to_dict()\n",
        "\n",
        "print(f\"Number of users in train_idx: {len(user_seqs)}\")\n",
        "\n",
        "#Define item universe for negative sampling\n",
        "all_items = np.array(sorted(iid_to_meta.keys()), dtype=np.int32)\n",
        "n_items   = len(all_items)\n",
        "print(f\"Item universe size (from iid_to_meta): {n_items}\")\n",
        "\n",
        "#Generate CTR examples: (uid, history, item, label)\n",
        "ctr_examples = []\n",
        "\n",
        "for uid, seq in user_seqs.items():\n",
        "    # Need at least 2 interactions to form history + next-item pair\n",
        "    if len(seq) < 2:\n",
        "        continue\n",
        "\n",
        "    user_pos_set = set(int(i) for i in seq)  # items this user has interacted with\n",
        "\n",
        "    #For each position t, seq[:t] is history and seq[t] is the positive target\n",
        "    for t in range(1, len(seq)):\n",
        "        history = [int(i) for i in seq[:t]]\n",
        "        target  = int(seq[t])\n",
        "\n",
        "        # Truncate history to last MAX_HISTORY_LEN_CTR items\n",
        "        hist_trunc = history[-MAX_HISTORY_LEN_CTR:]\n",
        "\n",
        "        #Positive example\n",
        "        ctr_examples.append(\n",
        "            {\n",
        "                \"uid\": int(uid),\n",
        "                \"history\": hist_trunc,\n",
        "                \"item\": target,\n",
        "                \"label\": 1,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        #Negative examples\n",
        "        for _ in range(NUM_NEGATIVES_PER_POS):\n",
        "            neg_item = None\n",
        "\n",
        "            # Simple rejection sampling: sample until we hit an item\n",
        "            # the user has never interacted with.\n",
        "            while True:\n",
        "                candidate_neg = int(rng.choice(all_items))\n",
        "                if candidate_neg not in user_pos_set:\n",
        "                    neg_item = candidate_neg\n",
        "                    break\n",
        "\n",
        "            ctr_examples.append(\n",
        "                {\n",
        "                    \"uid\": int(uid),\n",
        "                    \"history\": hist_trunc,\n",
        "                    \"item\": neg_item,\n",
        "                    \"label\": 0,\n",
        "                }\n",
        "            )\n",
        "\n",
        "print(f\"\\nBuilt {len(ctr_examples)} raw CTR examples before capping.\")\n",
        "\n",
        "#Shuffle and cap to MAX_TRAIN_EXAMPLES\n",
        "rng.shuffle(ctr_examples)\n",
        "\n",
        "if len(ctr_examples) > MAX_TRAIN_EXAMPLES:\n",
        "    ctr_examples = ctr_examples[:MAX_TRAIN_EXAMPLES]\n",
        "\n",
        "print(f\"After capping: {len(ctr_examples)} CTR examples.\")\n",
        "\n",
        "#Convert to DataFrame\n",
        "ctr_df = pd.DataFrame(ctr_examples)\n",
        "\n",
        "print(\"\\nCTR DataFrame head:\")\n",
        "print(ctr_df.head())\n",
        "\n",
        "print(\"\\nLabel distribution (0=NO, 1=YES):\")\n",
        "print(ctr_df[\"label\"].value_counts(normalize=True))\n",
        "\n",
        "#Train/val split (on rows)\n",
        "val_size = int(len(ctr_df) * VAL_FRACTION)\n",
        "train_df_ctr = ctr_df.iloc[:-val_size].reset_index(drop=True)\n",
        "val_df_ctr   = ctr_df.iloc[-val_size:].reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nFinal CTR df sizes â†’ total: {len(ctr_df)}, \"\n",
        "      f\"train: {len(train_df_ctr)}, val: {len(val_df_ctr)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjNwlajsWyks",
        "outputId": "622a759a-7808-4019-ddc1-3c807b10147e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building user sequences from train_idx for CTR...\n",
            "Number of users in train_idx: 14064\n",
            "Item universe size (from iid_to_meta): 18783\n",
            "\n",
            "Built 92944 raw CTR examples before capping.\n",
            "After capping: 15000 CTR examples.\n",
            "\n",
            "CTR DataFrame head:\n",
            "    uid                       history   item  label\n",
            "0  3048          [7521, 11188, 11471]  12280      0\n",
            "1  5409                         [980]   4487      0\n",
            "2  3728                         [756]   2989      1\n",
            "3  2856                  [2715, 3261]   8073      0\n",
            "4  6200  [13990, 14331, 14659, 15332]  13862      0\n",
            "\n",
            "Label distribution (0=NO, 1=YES):\n",
            "label\n",
            "1    0.504067\n",
            "0    0.495933\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Final CTR df sizes â†’ total: 15000, train: 13500, val: 1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Helper: Convert a list of iids into USER HISTORY lines\n",
        "def build_history_block(history_iids, iid_to_meta):\n",
        "    \"\"\"\n",
        "    Convert history iids into lines like:\n",
        "    - Title: X | Summary: Y\n",
        "    \"\"\"\n",
        "    lines = []\n",
        "    for iid in history_iids:\n",
        "        meta = iid_to_meta.get(int(iid), None)\n",
        "        if meta is None:\n",
        "            continue\n",
        "\n",
        "        title = meta.get(\"title\", \"\").strip()\n",
        "        summ  = meta.get(\"short_desc\", \"\").strip()\n",
        "\n",
        "        if title == \"\" and summ == \"\":\n",
        "            continue\n",
        "\n",
        "        if summ:\n",
        "            line = f\"- Title: {title} | Summary: {summ}\"\n",
        "        else:\n",
        "            line = f\"- Title: {title}\"\n",
        "        lines.append(line)\n",
        "\n",
        "    if len(lines) == 0:\n",
        "        lines.append(\"- No meaningful history available.\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# Helper: Convert one (history, item, label) into full text\n",
        "def build_ctr_prompt(history_iids, candidate_iid, label, iid_to_meta, eos_token=\"</s>\"):\n",
        "    meta = iid_to_meta.get(int(candidate_iid), {})\n",
        "\n",
        "    cand_title = meta.get(\"title\", \"\").strip() or \"Unknown Title\"\n",
        "    cand_summ  = meta.get(\"short_desc\", \"\").strip()\n",
        "\n",
        "    history_block = build_history_block(history_iids, iid_to_meta)\n",
        "\n",
        "    if cand_summ:\n",
        "        cand_block = f\"Title: {cand_title}\\nSummary: {cand_summ}\"\n",
        "    else:\n",
        "        cand_block = f\"Title: {cand_title}\"\n",
        "\n",
        "    # Convert label 1 â†’ YES, 0 â†’ NO\n",
        "    final_label = \"YES\" if label == 1 else \"NO\"\n",
        "\n",
        "    text = f\"\"\"You are a book recommendation assistant.\n",
        "Given a user's reading history and ONE candidate book, decide if the user is likely to enjoy the candidate.\n",
        "Answer with exactly one word: YES or NO.\n",
        "\n",
        "[USER HISTORY]\n",
        "{history_block}\n",
        "\n",
        "[CANDIDATE]\n",
        "{cand_block}\n",
        "\n",
        "[QUESTION]\n",
        "Will the user like this book?\n",
        "\n",
        "[ANSWER]\n",
        "{final_label}\n",
        "{eos_token}\n",
        "\"\"\"\n",
        "    return text\n",
        "\n",
        "# Build the \"text\" column for ctr_df\n",
        "print(\"Building text prompts for CTR fine-tuning...\")\n",
        "\n",
        "ctr_texts = []\n",
        "for idx, row in tqdm(ctr_df.iterrows(), total=len(ctr_df)):\n",
        "    hist_iids = row[\"history\"]\n",
        "    item_iid  = row[\"item\"]\n",
        "    label     = row[\"label\"]\n",
        "\n",
        "    text = build_ctr_prompt(\n",
        "        history_iids = hist_iids,\n",
        "        candidate_iid = item_iid,\n",
        "        label = label,\n",
        "        iid_to_meta = iid_to_meta,\n",
        "        eos_token = \"</s>\"\n",
        "    )\n",
        "    ctr_texts.append(text)\n",
        "\n",
        "ctr_df[\"text\"] = ctr_texts\n",
        "\n",
        "print(\"Example CTR prompt:\\n\")\n",
        "print(ctr_df[\"text\"].iloc[3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cLb-fDHayZI",
        "outputId": "9e852adf-784f-49e0-cc95-e50979b562fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building text prompts for CTR fine-tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15000/15000 [00:00<00:00, 20620.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example CTR prompt:\n",
            "\n",
            "You are a book recommendation assistant.\n",
            "Given a user's reading history and ONE candidate book, decide if the user is likely to enjoy the candidate.\n",
            "Answer with exactly one word: YES or NO.\n",
            "\n",
            "[USER HISTORY]\n",
            "- Title: The Stranger | Summary: Chris VanAllsburg has created another literary masterpiece\n",
            "- Title: Exporting America: Why Corporate Greed Is Shipping American Jobs Overseas | Summary: I think he needs to get a lesson in basic economics\n",
            "\n",
            "[CANDIDATE]\n",
            "Title: Thendara House (Darkover)\n",
            "Summary: \"Thendara House\" is a sequel, of sorts, to the previous Darkover novel \"The Shattered Chain\n",
            "\n",
            "[QUESTION]\n",
            "Will the user like this book?\n",
            "\n",
            "[ANSWER]\n",
            "NO\n",
            "</s>\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "# Use same hyperparams as before\n",
        "VAL_FRACTION = 0.1\n",
        "\n",
        "#Recompute split so train/val have the text column too\n",
        "val_size = int(len(ctr_df) * VAL_FRACTION)\n",
        "\n",
        "train_df_ctr = ctr_df.iloc[:-val_size].reset_index(drop=True)\n",
        "val_df_ctr   = ctr_df.iloc[-val_size:].reset_index(drop=True)\n",
        "\n",
        "print(f\"CTR df sizes â†’ total: {len(ctr_df)}, train: {len(train_df_ctr)}, val: {len(val_df_ctr)}\")\n",
        "\n",
        "#Sanity check\n",
        "print(\"\\nTrain CTR sample row:\")\n",
        "print(train_df_ctr.head(1)[[\"uid\", \"history\", \"item\", \"label\", \"text\"]])\n",
        "\n",
        "print(\"\\nVal CTR sample row:\")\n",
        "print(val_df_ctr.head(1)[[\"uid\", \"history\", \"item\", \"label\", \"text\"]])\n",
        "\n",
        "#Build HF datasets with only the 'text' field (for SFTTrainer)\n",
        "train_dataset_ctr = Dataset.from_pandas(train_df_ctr[[\"text\"]])\n",
        "val_dataset_ctr   = Dataset.from_pandas(val_df_ctr[[\"text\"]])\n",
        "\n",
        "print(\"\\nHF train_dataset_ctr:\", train_dataset_ctr)\n",
        "print(\"HF val_dataset_ctr:\", val_dataset_ctr)\n",
        "\n",
        "ctr_ds = DatasetDict({\n",
        "    \"train\": train_dataset_ctr,\n",
        "    \"val\":   val_dataset_ctr,\n",
        "})\n",
        "\n",
        "print(\"Train dataset size:\", len(ctr_ds[\"train\"]))\n",
        "print(\"Val dataset size:\", len(ctr_ds[\"val\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhQz81T2bHl3",
        "outputId": "56422cb1-16a0-4f86-9037-c684da07676a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CTR df sizes â†’ total: 15000, train: 13500, val: 1500\n",
            "\n",
            "Train CTR sample row:\n",
            "    uid               history   item  label  \\\n",
            "0  3048  [7521, 11188, 11471]  12280      0   \n",
            "\n",
            "                                                text  \n",
            "0  You are a book recommendation assistant.\\nGive...  \n",
            "\n",
            "Val CTR sample row:\n",
            "   uid history   item  label  \\\n",
            "0  632  [9706]  14019      0   \n",
            "\n",
            "                                                text  \n",
            "0  You are a book recommendation assistant.\\nGive...  \n",
            "\n",
            "HF train_dataset_ctr: Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 13500\n",
            "})\n",
            "HF val_dataset_ctr: Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 1500\n",
            "})\n",
            "Train dataset size: 13500\n",
            "Val dataset size: 1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q unsloth transformers accelerate bitsandbytes trl datasets\n",
        "\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n"
      ],
      "metadata": {
        "id": "_oBc_-iA5bmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\"\n",
        "max_seq_len = 1024\n",
        "\n",
        "#Load base quantized Mistral\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name     = MODEL_NAME,\n",
        "    max_seq_length = max_seq_len,\n",
        "    dtype          = None,          # auto fp16/bf16\n",
        "    load_in_4bit   = True,\n",
        ")\n",
        "\n",
        "print(\"Base model loaded.\")\n",
        "print(\"EOS token:\", tokenizer.eos_token, tokenizer.eos_token_id)\n",
        "\n",
        "#Attach LoRA adapters ONCE\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0.0,            # HF-style\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None,\n",
        ")\n",
        "\n",
        "print(\"LoRA model ready.\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size = 2,\n",
        "    gradient_accumulation_steps = 4,\n",
        "    warmup_steps = 10,\n",
        "    max_steps = 300,\n",
        "    learning_rate = 2e-4,\n",
        "    fp16 = not is_bfloat16_supported(),\n",
        "    bf16 = is_bfloat16_supported(),\n",
        "    logging_steps = 10,\n",
        "    optim = \"adamw_8bit\",\n",
        "    weight_decay = 0.01,\n",
        "    lr_scheduler_type = \"linear\",\n",
        "    seed = 3407,\n",
        "    output_dir = \"ctr_lora_amazonbooks_hf_style\",\n",
        "    report_to = \"none\",\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = ctr_ds[\"train\"],\n",
        "    eval_dataset  = ctr_ds[\"val\"],\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_len,\n",
        "    packing = False,\n",
        "    # dataset_num_proc = 2,\n",
        "    args = training_args,\n",
        ")\n",
        "\n",
        "print(\"Trainer ready.\")\n",
        "\n",
        "#START TRAINING\n",
        "print(\"\\nStarting CTR fine-tuning...\\n\")\n",
        "train_output = trainer.train()\n",
        "print(\"Training complete!\")\n",
        "print(train_output)\n",
        "\n",
        "#validation\n",
        "val_metrics = trainer.evaluate()\n",
        "print(\"Validation metrics:\", val_metrics)\n",
        "\n",
        "#Save LoRA adapter + tokenizer for later scoring\n",
        "save_dir = \"ctr_lora_amazonbooks_model\"\n",
        "\n",
        "model.save_pretrained(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "print(f\"\\nSaved LoRA model + tokenizer to: {save_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "64858847608242d3af233614e7362c5c",
            "9cfd361539324e74a2ed48ca30f64391",
            "092c5b7377f7448598a67ba5f7c0b066",
            "e4a12d2721794783a79a6afcf1f86f58",
            "df58f8823c1e442190a762e45d95f128",
            "772856ee2cd34ae28841d100790446bc",
            "9f82055c7d05427b92fc9c9ea20097dc",
            "7b593650a2e44a1f9b238f4b421ff7d6",
            "d3df494424b642359b66e89f8cd99f96",
            "c90b07ee3f4b4bd9b9b5de0b8570fb78",
            "eb1806b5029e406c889e94cd2b76d004",
            "71d7452243084fc9ae8bc1aa2bf9036b",
            "c2f14ea88277411ea2a7422309696adf",
            "9dd59da73909441c964761e63bdee4b0",
            "89d892135e6449908592d6b50d279c4c",
            "f8d3afc2039e4e668febc1dcd5580960",
            "ab1d9e8de2fd4e1592036d0246e76c4c",
            "3925eeecd70642e692468e924364443a",
            "3fb0207f06594c76ab4e8dd4d6e4cfcc",
            "150d175b76ea48948961a3e4dfe16800",
            "85ac67908ba342bdb56b48a6a1d0a6ac",
            "5f8ec250c96d4cfc9dbcc1d6597be0cb"
          ]
        },
        "id": "H5bq3kzoUyUe",
        "outputId": "9b2ceb15-abf3-431e-f7ff-810c527ce8d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.12.4: Fast Mistral patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Base model loaded.\n",
            "EOS token: </s> 2\n",
            "LoRA model ready.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=16):   0%|          | 0/13500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64858847608242d3af233614e7362c5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=16):   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71d7452243084fc9ae8bc1aa2bf9036b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainer ready.\n",
            "\n",
            "Starting CTR fine-tuning...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 13,500 | Num Epochs = 1 | Total steps = 300\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 41,943,040 of 7,289,966,592 (0.58% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 16:34, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.094800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.246900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.170700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.118200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.094200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.036600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.061000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.033200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.050700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.929000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.046900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.939200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.989000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.951400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.014700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.889900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.966200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.949300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.873700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.916600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.899900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.914300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.817700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.896600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.881200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.887800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.883500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.869000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.897100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Not an error, but MistralForCausalLM does not accept `num_items_in_batch`.\n",
            "Using gradient accumulation will be very slightly less accurate.\n",
            "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete!\n",
            "TrainOutput(global_step=300, training_loss=1.0107340621948242, metrics={'train_runtime': 1004.273, 'train_samples_per_second': 2.39, 'train_steps_per_second': 0.299, 'total_flos': 2.540485483089101e+16, 'train_loss': 1.0107340621948242, 'epoch': 0.17777777777777778})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='188' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [188/188 02:30]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation metrics: {'eval_loss': 0.8551682829856873, 'eval_runtime': 152.0519, 'eval_samples_per_second': 9.865, 'eval_steps_per_second': 1.236, 'epoch': 0.17777777777777778}\n",
            "\n",
            "Saved LoRA model + tokenizer to: ctr_lora_amazonbooks_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATION"
      ],
      "metadata": {
        "id": "UIH64OiXax-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "#Using same value as in CTR training\n",
        "MAX_HISTORY_LEN_CTR = 10\n",
        "\n",
        "#Build full sequences from train_idx\n",
        "train_sorted_eval = train_idx.sort_values([\"uid\", \"ts\"])\n",
        "user_seqs_eval = train_sorted_eval.groupby(\"uid\")[\"iid\"].apply(list).to_dict()\n",
        "\n",
        "print(f\"Number of users with training history: {len(user_seqs_eval)}\")\n",
        "\n",
        "def get_recent_history_iids(uid, max_len=MAX_HISTORY_LEN_CTR):\n",
        "    \"\"\"\n",
        "    Return the last `max_len` items from the user's training sequence.\n",
        "    If no history is found, return [].\n",
        "    \"\"\"\n",
        "    seq = user_seqs_eval.get(int(uid), [])\n",
        "    if not seq:\n",
        "        return []\n",
        "    return [int(i) for i in seq[-max_len:]]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grkjPWdjgkjQ",
        "outputId": "bcbbc0ff-fbe3-44b7-a724-dbe0ca4beeff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users with training history: 14064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hit_at_k(ranked_ids, target_id, k=10):\n",
        "    \"\"\"\n",
        "    ranked_ids: list of item ids sorted by predicted score (best first)\n",
        "    target_id:  the true next item\n",
        "    k:         cutoff rank\n",
        "\n",
        "    Returns 1 if target_id is in top-k, else 0.\n",
        "    \"\"\"\n",
        "    top_k = ranked_ids[:k]\n",
        "    return 1 if target_id in top_k else 0\n",
        "\n",
        "import math\n",
        "\n",
        "def ndcg_at_k(ranked_ids, target_id, k=10):\n",
        "    \"\"\"\n",
        "    ranked_ids: list of item ids sorted by predicted score (best first)\n",
        "    target_id:  true item id\n",
        "    k:         cutoff\n",
        "\n",
        "    Returns NDCG@K value (0.0 to 1.0).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        rank = ranked_ids.index(target_id) + 1\n",
        "    except ValueError:\n",
        "        return 0.0\n",
        "\n",
        "    if rank > k:\n",
        "        return 0.0\n",
        "\n",
        "    dcg = 1.0 / math.log2(rank + 1)\n",
        "    return dcg\n"
      ],
      "metadata": {
        "id": "aM5VDD5Dw12b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_history_block_ctr(history_iids, iid_to_meta):\n",
        "    lines = []\n",
        "    for iid in history_iids:\n",
        "        meta = iid_to_meta.get(int(iid))\n",
        "        if meta is None:\n",
        "            continue\n",
        "        title = meta.get(\"title\", \"\").strip()\n",
        "        summ  = meta.get(\"short_desc\", \"\").strip()\n",
        "        if not title and not summ:\n",
        "            continue\n",
        "        if summ:\n",
        "            line = f\"- Title: {title} | Summary: {summ}\"\n",
        "        else:\n",
        "            line = f\"- Title: {title}\"\n",
        "        lines.append(line)\n",
        "\n",
        "    if not lines:\n",
        "        lines.append(\"- No meaningful history available.\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "def build_ctr_inference_prompt(history_iids, candidate_iid, iid_to_meta):\n",
        "    meta = iid_to_meta.get(int(candidate_iid), {})\n",
        "    cand_title = meta.get(\"title\", \"\").strip() or \"Unknown Title\"\n",
        "    cand_summ  = meta.get(\"short_desc\", \"\").strip()\n",
        "\n",
        "    history_block = build_history_block_ctr(history_iids, iid_to_meta)\n",
        "\n",
        "    if cand_summ:\n",
        "        cand_block = f\"Title: {cand_title}\\nSummary: {cand_summ}\"\n",
        "    else:\n",
        "        cand_block = f\"Title: {cand_title}\"\n",
        "\n",
        "    text = f\"\"\"You are a book recommendation assistant.\n",
        "Given a user's reading history and ONE candidate book, decide if the user is likely to enjoy the candidate.\n",
        "Answer with exactly one word: YES or NO.\n",
        "\n",
        "[USER HISTORY]\n",
        "{history_block}\n",
        "\n",
        "[CANDIDATE]\n",
        "{cand_block}\n",
        "\n",
        "[QUESTION]\n",
        "Will the user like this book?\n",
        "\n",
        "[ANSWER]\n",
        "\"\"\"\n",
        "    return text\n",
        "\n",
        "import torch\n",
        "\n",
        "def answer_logprob(model, tokenizer, prompt, answer_text, max_seq_length):\n",
        "    \"\"\"\n",
        "    Compute log p(answer_text | prompt) under the LM.\n",
        "    Works even if answer_text is multi-token (like 'YES').\n",
        "    \"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    #Tokenize prompt alone\n",
        "    prompt_ids = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=max_seq_length,\n",
        "    )[\"input_ids\"][0]\n",
        "\n",
        "    #Tokenize prompt + answer together\n",
        "    full = tokenizer(\n",
        "        prompt + answer_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=max_seq_length,\n",
        "    )\n",
        "    input_ids     = full[\"input_ids\"][0].to(device)\n",
        "    attention_mask = full[\"attention_mask\"][0].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids=input_ids.unsqueeze(0),\n",
        "            attention_mask=attention_mask.unsqueeze(0),\n",
        "        )\n",
        "        logits = outputs.logits[0]  #[seq_len, vocab]\n",
        "\n",
        "    seq_len    = input_ids.shape[0]\n",
        "    prompt_len = prompt_ids.shape[0]\n",
        "\n",
        "    #Answer tokens = input_ids[prompt_len : seq_len]\n",
        "    answer_token_ids = input_ids[prompt_len:seq_len]\n",
        "\n",
        "    #Logits predicting those tokens are at positions [prompt_len-1 : seq_len-1]\n",
        "    logits_for_answer = logits[prompt_len - 1 : seq_len - 1, :]\n",
        "    log_probs = torch.log_softmax(logits_for_answer, dim=-1)\n",
        "\n",
        "    logprob_sum = 0.0\n",
        "    for pos, tok_id in enumerate(answer_token_ids):\n",
        "        logprob_sum += log_probs[pos, tok_id].item()\n",
        "\n",
        "    return logprob_sum\n",
        "\n",
        "def score_candidate_yes_prob(model, tokenizer, history_iids, candidate_iid,\n",
        "                             iid_to_meta, max_seq_length):\n",
        "    \"\"\"\n",
        "    Return p(YES | history, candidate) using full-sequence log-probs\n",
        "    for 'YES' vs 'NO'.\n",
        "    \"\"\"\n",
        "    prompt = build_ctr_inference_prompt(history_iids, candidate_iid, iid_to_meta)\n",
        "\n",
        "    logp_yes = answer_logprob(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        prompt=prompt,\n",
        "        answer_text=\"YES\",\n",
        "        max_seq_length=max_seq_length,\n",
        "    )\n",
        "\n",
        "    logp_no = answer_logprob(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        prompt=prompt,\n",
        "        answer_text=\"NO\",\n",
        "        max_seq_length=max_seq_length,\n",
        "    )\n",
        "\n",
        "    logits = torch.tensor([logp_no, logp_yes])  # [NO, YES]\n",
        "    probs  = torch.softmax(logits, dim=0)\n",
        "    p_yes  = probs[1].item()\n",
        "    return p_yes\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Pick one VAL user row to inspect\n",
        "sample_row = val_eval.iloc[1]\n",
        "\n",
        "uid          = int(sample_row[\"uid\"])\n",
        "candidate_id = int(sample_row[\"candidates\"][5])\n",
        "target_id    = int(sample_row[\"target\"])\n",
        "\n",
        "history_iids = get_recent_history_iids(uid, max_len=MAX_HISTORY_LEN_CTR)\n",
        "\n",
        "#Build and print the prompt\n",
        "sample_prompt = build_ctr_inference_prompt(history_iids, candidate_id, iid_to_meta)\n",
        "\n",
        "print(\"SAMPLE CTR INFERENCE PROMPT \\n\")\n",
        "print(sample_prompt)\n",
        "\n",
        "# Compute and print p(YES | history, candidate)\n",
        "p_yes = score_candidate_yes_prob(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    history_iids=history_iids,\n",
        "    candidate_iid=candidate_id,\n",
        "    iid_to_meta=iid_to_meta,\n",
        "    max_seq_length=max_seq_len,\n",
        ")\n",
        "\n",
        "print(\"\\n SAMPLE SCORE \")\n",
        "print(f\"UID: {uid}\")\n",
        "print(f\"Candidate IID: {candidate_id}\")\n",
        "print(f\"Target IID:    {target_id}\")\n",
        "print(f\"p(YES | history, candidate) = {p_yes:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqATQDM1gtzr",
        "outputId": "7e97f91e-7a47-44fb-b043-b179b681c81e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== SAMPLE CTR INFERENCE PROMPT =====\n",
            "\n",
            "You are a book recommendation assistant.\n",
            "Given a user's reading history and ONE candidate book, decide if the user is likely to enjoy the candidate.\n",
            "Answer with exactly one word: YES or NO.\n",
            "\n",
            "[USER HISTORY]\n",
            "- Title: The Awakening: Complete, Authoritative Text With Biographical and Historical Contexts, Critical History, and Essays from Five Contemporary Critical ... (Case Studies in Contemporary Criticism) | Summary: From reading the readers' responses, I believe that this classic is still too subtle and complex to be appreciated by most\n",
            "- Title: Awakening: Kate Chopin Pb (Case Studies in Contemporary) | Summary: I had to have this for my English CompII class\n",
            "- Title: The Awakening | Summary: This was an excellent ghost story! Usually with any ghost/mystery book, you can guess the ending mid way through the book, but not this one! Mrs\n",
            "- Title: Public Secrets | Summary: I loved this book but am giving it only 4 stars because the editing was so awful in this Kindle edition\n",
            "- Title: Dracula (G. K. Hall (Large Print)) | Summary: Very wordy but interesting read\n",
            "\n",
            "[CANDIDATE]\n",
            "Title: The Lord of the Rings Trilogy: Three Volumes in Slipcase\n",
            "Summary: Just wonderful! From one beautiful golden edged page to the last, it was pure joy\n",
            "\n",
            "[QUESTION]\n",
            "Will the user like this book?\n",
            "\n",
            "[ANSWER]\n",
            "\n",
            "\n",
            "===== SAMPLE SCORE =====\n",
            "UID: 1\n",
            "Candidate IID: 14470\n",
            "Target IID:    8721\n",
            "p(YES | history, candidate) = 0.5622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_llm_ctr_reranker(eval_df, model, tokenizer, iid_to_meta,\n",
        "                          max_seq_length, k=10, desc=\"VAL\"):\n",
        "    hits  = []\n",
        "    ndcgs = []\n",
        "\n",
        "    rows = eval_df.to_dict(\"records\")\n",
        "\n",
        "    for row in tqdm(rows, desc=f\"Evaluating CTR LLM on {desc}\", ncols=100):\n",
        "        uid            = int(row[\"uid\"])\n",
        "        candidate_iids = [int(i) for i in row[\"candidates\"]]\n",
        "        target_iid     = int(row[\"target\"])\n",
        "\n",
        "        history_iids = get_recent_history_iids(uid, max_len=MAX_HISTORY_LEN_CTR)\n",
        "\n",
        "        scores = []\n",
        "        for iid in candidate_iids:\n",
        "            p_yes = score_candidate_yes_prob(\n",
        "                model=model,\n",
        "                tokenizer=tokenizer,\n",
        "                history_iids=history_iids,\n",
        "                candidate_iid=iid,\n",
        "                iid_to_meta=iid_to_meta,\n",
        "                max_seq_length=max_seq_length,\n",
        "            )\n",
        "            scores.append(p_yes)\n",
        "\n",
        "        ranked = sorted(zip(candidate_iids, scores),\n",
        "                        key=lambda x: x[1],\n",
        "                        reverse=True)\n",
        "        ranked_ids = [iid for iid, _ in ranked]\n",
        "\n",
        "        hit  = hit_at_k(ranked_ids, target_iid, k=k)\n",
        "        ndcg = ndcg_at_k(ranked_ids, target_iid, k=k)\n",
        "\n",
        "        hits.append(hit)\n",
        "        ndcgs.append(ndcg)\n",
        "\n",
        "    hr_mean   = float(np.mean(hits))  if hits  else 0.0\n",
        "    ndcg_mean = float(np.mean(ndcgs)) if ndcgs else 0.0\n",
        "\n",
        "    print(f\"\\n[{desc}] HR@{k}:   {hr_mean:.4f}\")\n",
        "    print(f\"[{desc}] NDCG@{k}: {ndcg_mean:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"hr_at_k\": hr_mean,\n",
        "        \"ndcg_at_k\": ndcg_mean,\n",
        "    }"
      ],
      "metadata": {
        "id": "cYfum_1Mg1s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K_VALUES = [5, 10, 20]\n",
        "\n",
        "val_results = {}\n",
        "\n",
        "for k in K_VALUES:\n",
        "    print(f\"\\n Evaluating CTR LLM on VAL at k = {k} \")\n",
        "    results_val = eval_llm_ctr_reranker(\n",
        "        eval_df=val_eval,\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        iid_to_meta=iid_to_meta,\n",
        "        max_seq_length=max_seq_len,\n",
        "        k=k,\n",
        "        desc=f\"VAL@{k}\",\n",
        "    )\n",
        "    val_results[k] = results_val\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Euf-tiyzg2VA",
        "outputId": "a1fd7dc8-e122-4d8e-9349-59d8edf9b599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluating CTR LLM on VAL at k = 5 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating CTR LLM on VAL@5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [35:27<00:00, 21.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[VAL@5] HR@5:   0.4500\n",
            "[VAL@5] NDCG@5: 0.3859\n",
            "\n",
            " Evaluating CTR LLM on VAL at k = 10 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating CTR LLM on VAL@10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [35:28<00:00, 21.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[VAL@10] HR@10:   0.5400\n",
            "[VAL@10] NDCG@10: 0.4136\n",
            "\n",
            " Evaluating CTR LLM on VAL at k = 20 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating CTR LLM on VAL@20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [35:29<00:00, 21.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[VAL@20] HR@20:   0.6600\n",
            "[VAL@20] NDCG@20: 0.4434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_VALUES = [5, 10, 20]\n",
        "test_results = {}\n",
        "\n",
        "for k in K_VALUES:\n",
        "    print(f\"\\n Evaluating CTR LLM on TEST at k = {k} \")\n",
        "    results_test = eval_llm_ctr_reranker(\n",
        "        eval_df=test_eval,\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        iid_to_meta=iid_to_meta,\n",
        "        max_seq_length=max_seq_len,\n",
        "        k=k,\n",
        "        desc=f\"TEST@{k}\",\n",
        "    )\n",
        "    test_results[k] = results_test\n",
        "\n",
        "print(\"\\nFinal CTR LLM results:\")\n",
        "print(\"TEST:\", results_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVIO_pbrneb_",
        "outputId": "d13c3a54-ae71-451d-8fd7-63cdc2cd98d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluating CTR LLM on TEST at k = 5 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating CTR LLM on TEST@5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [35:28<00:00, 21.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[TEST@5] HR@5:   0.4700\n",
            "[TEST@5] NDCG@5: 0.3692\n",
            "\n",
            " Evaluating CTR LLM on TEST at k = 10 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating CTR LLM on TEST@10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [35:28<00:00, 21.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[TEST@10] HR@10:   0.5500\n",
            "[TEST@10] NDCG@10: 0.3941\n",
            "\n",
            " Evaluating CTR LLM on TEST at k = 20 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating CTR LLM on TEST@20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [35:28<00:00, 21.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[TEST@20] HR@20:   0.6600\n",
            "[TEST@20] NDCG@20: 0.4208\n",
            "\n",
            "Final CTR LLM results:\n",
            "TEST: {'hr_at_k': 0.66, 'ndcg_at_k': 0.42082813761563354}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss_values = [\n",
        "    2.094800,\n",
        "    1.246400,\n",
        "    1.170400,\n",
        "    1.115600,\n",
        "    1.093300,\n",
        "    1.036100,\n",
        "    1.061000,\n",
        "    1.002100,\n",
        "    1.031200,\n",
        "    1.049400,\n",
        "    0.926500,\n",
        "    1.046900,\n",
        "    0.939400,\n",
        "    0.986300,\n",
        "    0.950700,\n",
        "    1.013700,\n",
        "    0.888900,\n",
        "    0.965200,\n",
        "    0.950300,\n",
        "    0.873200,\n",
        "    0.916100,\n",
        "    0.899700,\n",
        "    0.912800,\n",
        "    0.816000,\n",
        "    0.896500,\n",
        "    0.880600,\n",
        "    0.887600,\n",
        "    0.882200,\n",
        "    0.868100,\n",
        "    0.896700,\n",
        "]\n",
        "steps = list(range(10, 10 * (len(loss_values) + 1), 10))\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(steps, loss_values, marker='o', linestyle='-', color='blue')\n",
        "\n",
        "plt.title(\"Training Loss vs Steps (Mistral-7B CTR Fine-Tuning)\")\n",
        "plt.xlabel(\"Global Step\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "plt.grid(True)\n",
        "plt.xticks(steps, rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "OPFd3TjJkF2R",
        "outputId": "d4db47ed-a572-426b-d2fd-f2ebc4eddf3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}